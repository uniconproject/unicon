\chapter{Further Optimizing the Icon Compiler}

This chapter details a set of optimizations that were made to the Icon
compiler by Anthony Jones in 1996. Additional work improving the
optimizing compiler, and making it work with the Unicon translator,
was performed by Mike Wilder and is described in his M.S. thesis (2005).
Work on adding concurrency support and porting to MS Windows was
done by Shea Newton and Ian Westrope around 2015.

Several optimizations are implemented to the type inferencing system
and the intermediate code generation with the goals of improving
execution time of the generated executable and lower memory
requirements. The single biggest impact of both Anthony Jones' and
Mike Wilder's work has been to solve the memory space scalability
problem for type inferencing. It did not hurt that in the intervening
years, main memories in typical computers went from 4MB to 4GB, but
Jones and then Wilder reduced both the large constants as well as the
space complexity of type inferencing.

\section{Introduction}

Compiler optimizations is a difficult but exciting subject. There are
a wide variety of ways a compiler could be optimized. There are also
different levels that optimizations may be performed on. For example,
one level of optimization deals with the front end and intermediate
code generation. Some examples of these optimizations include common
subexpression elimination, copy propagation, dead-code elimination,
constant folding, loop unrolling, and strength reduction.

Another level of optimiztion is machine specific, which might include
efficient use of register assignments, using platform specific
instructions that offer greater performance, or doing peephole
transformations [ASU86]. However, the optimizations proposed for the
Icon compiler are not platform specific because of the way the Icon
compiler generates code. The Icon compiler's intermediate code is
actually C. This means that Iconc translates Icon code into C code
which then calls the native C compiler to finish the job.

Another way a compiler can be optimized is by improving the
performance of the compiler itself and not the generated code. These
optimizations include improving memory usage or making internal data
structures more efficient.  The optimizations proposed for the Icon
compiler deal exclusively with the front end and intermediate code
stages of compilation and improving the performance of the compiler
itself.

Specifically, one of the main motivations behind this project was to
make the compiler more effective by improving the memory usage for the
type inferencing system because the Icon compiler was running out of
memory compiling medium-large length programs. The next concern was
the intermediate code generation. An examination of the intermediate
code provided many areas of improvement. Some of the optimizations
possible were eliminating redundant Icon system calls, replacing Icon
literals with C literals, and eliminating unnecessary logic in
variable initialization blocks.

\subsection{Areas Where Iconc Can Be Improved}

The advantage of iconc's compiled code is that it is many times faster
than interpreted code. Unfortunately, Iconc contains some major
problems that prevents the compiler from being widely used. The next
few sections describe the components of the existing compiler that
were optimized in this project, and each section details the reasons
for improvement.  These optimizations were originally performed on the
iconc source from Icon Version 9. The optimized version of the
compiler was referred to as UTSA Iconc and later became a standard part
of the Unicon language distribution.

\bigskip

{\sffamily Type Inference}

Variables in Icon are implicitly typed and do not require a
declaration of a specific type (Walker 1991a). All type conversions
are implicit in assignments and computations (Walker 1992a). In
order to avoid type checks at run-time, the Icon compiler keeps track
of the type of each variable and \textit{infers} the types that each
variable may hold. The language has all the ``normal'' types such as
integers, floating point numbers, strings, and other common types, but
it also has complex structure types such as character sets, lists,
tables, and records. The type inferencing model allocates a unique
type to each source location at which heterogeneous structure types
such as lists or records are created. The Icon compiler represents all
the possible types as a bit vector with each bit position representing
a specific type. In the course of compiling a large program, the
number of total types, and therefore the size of the bit vectors, can
skyrocket.

{\sffamily Redundant Function Calls}

Icon has a macro named \texttt{Poll()} which is called every so often
to handle certain system events such as processing window system
events. The current compiler does an inefficient job of placing these
function calls in the generated code. Often there will be two calls to
\texttt{Poll} one right after the other or a simple assignment between
two calls. The objective of this part is to remove the redundancy and
let a reasonable number of calls remain.

{\sffamily Constant Propagation}

Simple literals appearing in Icon source code are assigned into the
local variable descriptor table within a procedure. This descriptor
table is an array of compilcated structures and pointers that incurs
many memory references simply for a constant. It is doubtful that
even the most robust C compilers would be able to recognize these
values as constants and propagate them accordingly. The objective is
to remove assignments of constants into the descriptor table and
replace references to those descriptor locations with constant values.

{\sffamily Variable Initialization}

At the beginning of every intermediate procedure there are several
loops that initialize local variables and parameters.  Sometimes these
loops initialize only one or two variables. In certain situations the
loop will not be executed at all, but the code for the loop is still
generated, requiring a comparison when the program executes. The
object of this part is to simplify the initialization loops and to
remove loops that have no effect.

\subsection{Changes to the Compiler Source}

All the changes made to the Icon compiler in order to implement these
optimizations were done with C compiler directives so that each
optimization can be turned on or off during compilation.

All directives are included in \textfn{src/c/define.h}. The following
code turns on all optimizations which are type, redundant functions,
literal propagation, and loop optimizations respectively.

\goodbreak
\begin{iconcode}
\#ifndef OptimizeType\\
\#define OptimizeType\\
\#endif\\
\\
\#ifndef OptimizePoll\\
\#define OptimizePoll\\
\#endif\\
\\
\#ifndef OptimizeLit\\
\#define OptimizeLit\\
\#endif\\
\\
\#ifndef OptimizeLoop\\
\#define OptimizeLoop\\
\#define LoopThreshold \ 6\\
\#endif\\
\end{iconcode}


In the last directive, \texttt{LoopThreshold} is declared to have the
value of 6. This constant is used in the loop unrolling optimizations
and is present so that the user can control this value. It simply is a
limit on the number of entries that may be unrolled in variable
initialization loops.


\section{Optimizing the Type Representation}

The first area of optimization is the representation of types. Iconc
maintains a structure for each variable that contains information
about that variable, including a bit vector with each bit representing
a particular type used in the program. When a bit vector is allocated
it is one of three possible sizes. The first size is composed of first
class types which are those built in types plus user defined types
that are utilized. The second size consists of the first class types
plus intermediate value types. Lastly, there is the number of total
types in the database. The database refers to the collection of all
builtin operations, their number of parameters and types, and the type
for the return value.

Data was gathered from \textit{Ctree}, a circular tree visualization
tool. This program consists of \~{}500 lines of source code. The
number of possible first class types is 209 which translates to a 28
byte bit vector. Note that bit vectors are allocated in multiples of a
word (4 bytes). During the course of the compilation, 137,946 bit
vectors are allocated. The number of first class types plus types for
intermediate values is 1,012, resulting in a 128 byte bit vector, and
18,925 vectors of this size are allocated. Lastly, the number of
database types is 1,369 types, using a 172 byte bit vector with only
121 allocations of this size. The total memory requirement for the bit
vectors is 6.22 megabytes. This information is summarized in Figure
24-1.

\begin{center}
\tablefirsthead{\hline
{\itshape Vector Type} &
{\itshape Number of Types} &
{\itshape Number Allocated} &
{\itshape Required Memory (MB)}\\}
\tablehead{\hline
{\itshape Vector Type} &
{\itshape Number of Types} &
{\itshape Number Allocated} &
{\itshape Required Memory (MB)}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.2191598in}|m{1.1629599in}|m{1.2455599in}|m{1.6080599in}|}
\hline
 first class &
\raggedleft 209 &
\raggedleft 137946 &
\raggedleft\arraybslash 3.8\\\hline
 intermediate class &
\raggedleft 1012 &
\raggedleft 18925 &
\raggedleft\arraybslash 2.4\\\hline
 database class &
\raggedleft 1369 &
\raggedleft 121 &
\raggedleft\arraybslash 0.02\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-1: Bit Vector Sizes
\par}


Figure 24-2 is an example of what a bit vector from \textit{Ctree}
might look like. This example shows the division between the three
type classes. Within the partition for first class types is bit 0
which represents an integer and bit 6 which is a real. Within the
intermediate types partition, bit 209 represents an instance of a
\texttt{cnode} record and an instance of a list variable, and bit 232
is an instance of a variable that is of the list type. Every instance
of a list or an aggregate type such as a record results in a new type
that gets its own bit in the bit vector.

Lastly, within the database class are builtin operations. The
functions for random number (\texttt{O0z7\_random}) and subtraction
(\texttt{O114\_subc}) are assigned bits 1,012 and 1,368
respectively. The functions are builtin to the Icon compiler and are
assigned their own types in the bit vector.

\bigskip

{\centering\selectlanguage{english}
  {\color{red} Missing Figure}\\
Figure 24-2: Sample Bit Vector
\par}

Additional tests were run on a 25,000 line Icon (really Idol) program
called \textit{Freedom in the Galaxy}, which was a semester long
effort by Dr. Jeffery's Software Engineering class. The program has
hundreds of variables, but object-orientation requires many additional
intermediate variables and dramatically increases the number and
size of type vectors allocated during compilation. \textit{Freedom in
the Galaxy} has 12,591 different distinct types including builtin,
intermediate, and database types. This is an example of a program that
ran out of memory during compilation with iconc on typical
workstations in the mid-1990's, motivating space improvements.

\subsection{New Type Representation}

The first order of business was to develop a new way to represent type
information. The first idea was to utilize the pointers to a type
vector. All type vectors are pointers to arrays of integers, and the
initial plan was to change a type vector's pointer to be not aligned
on a 4 byte boundary in the case that the type vector only represents
a simple integer.

Unfortunately, it was discovered that several different locations
referenced the same type vector, and any change to one would not be
apparent to the other. The second plan which was actually adopted was
to create a structure that could contain a packed representation of a
pointer to a full length type vector. This allowed multiple variables
to reference the same structure which would always be current since
only the fields of a structure were being modified.  The following
structure is the new type vector.

\goodbreak
\begin{iconcode}
struct typinfo \{\\
\>unsigned int *bits;\\
\>unsigned int packed;\\
\};\\
\end{iconcode}


The \texttt{bits} field is a pointer to an array of unsigned integers
which hold the full type representation of the variable. The
\texttt{packed} field serves two purposes. First, the lower 24 bits of
the integer are reserved for the length of this type vector which
corresponds to either the first class, intermediate class, or database
class type. This information is required in case a full length vector
needs to be allocated. Secondly, the upper 8 bits will contain the
packed representation of the type vector. These bits are set by ORing
the field with enumerated constants. Figure 25-3 lists the possible
values of this field.

\begin{center}
\tablefirsthead{\hline
 Type &
 Value &
 Description\\}
\tablehead{\hline
 Type &
 Value &
 Description\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{0.6629598in}|m{0.42545983in}|m{0.8122598in}|}
\hline
\texttt{ NULL\_T} &
\raggedleft 1 &
 Null type\\\hline
 \texttt{REAL\_T} &
\raggedleft 2 &
 Real type\\\hline
 \texttt{INT\_T} &
\raggedleft 4 &
 Integer type\\\hline
 \texttt{CSET\_T} &
\raggedleft 8 &
 C Set type\\\hline
 \texttt{STR\_T} &
\raggedleft 16 &
 String type\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 25-3: Valid Packed Types
\par}

The \texttt{typinfo} structure and defined constants for builtin types
were added to \textfn{csym.h}.

\subsection{How Type Allocation Works}

The new scheme for the type representation is actually rather
straightforward. Similar to the old method, a call to
\texttt{alloc\_typ} is made that returns a new type vector. The old
method simply returned a pointer of type \texttt{unsigned int} to a
portion of memory of sufficient size to hold the requested number of
types while the new method returns a pointer to \texttt{struct
typinfo}. This structure contains a packed representation of the type
information which holds the most frequently used types such as
integers, reals, strings, C sets, and the null value. This requires
only an integer which is four bytes. The size of each bit vector is
also encoded in this integer as explained earlier. The structure also
has the capacity to hold a pointer to a region of memory that can
contain an entire type vector in the event that this type vector needs
to represent more than the builtin five types. The entire structure
occupies only eight bytes.

In reality, \texttt{alloc\_typ} does not allocate \texttt{struct
typinfo} structures one at a time. Because an enormous number of these
structures are allocated during the compilation of a program,
\texttt{alloc\_typ} allocates a large number of these structures at
once. Currently, these structures are allocated in blocks of
400,000. This is done to reduce the overhead that \texttt{malloc}
requires when allocated blocks of memory. Every time memory is
allocated \texttt{malloc} needs extra memory (usually around 2-4
bytes) for bookkeeping purposes. As you can see, over 800,000 bytes
are saved by allocating this large block of structures. Additionally,
\texttt{malloc} is generally slow so this change will improve upon
compile time.

The five types that were chosen to be represented were integers,
reals, strings, csets, and null. This is because the Icon compiler
keeps a global variable for each one of these types that specifies
which bit position it is kept in for all bit vectors. Other types such
as lists or tables were not suitable because the compiler assigns them
a unique type and bit position for each occurrence of the variable.

During normal execution, all requests for a type vector return the new
type vector with the \texttt{packed} field initialized to zero. It
is important to note that the null data type is distinct from having
no type at all. Through the course of the compilation, the compiler
will either call a function to set bits in the vector or check to see
if a particular bit is set that corresponds to some type. When the
compiler is checking for the presence of a type, the type structure is
checked for either a compact or full representation. Once that is
known, a simple mask is created to see if the requested type is
present. However, the process becomes somewhat more complicated when
the compiler requests that a bit is to be set. First, a check is
made to determine whether the type structure contains the compact or
full type vector. If the requested type is an integer, real, string,
character set or the null value and the type structure uses the
compact vector, then the appropriate bit is set in the compact
vector. On the other hand, if the requested type is not one of the
special five types, a full length vector must be allocated, the
compact types must be copied into it, and the new type must also be
set. The last possible situation is if the full type vector already
exists in the type structure which simply means the requested type can
be set without any special actions or additional tests.

In order to accomplish this, several functions that manipulate the
type vectors had to be changed to accomodate the new representation.
The following sections detail the changes and/or reorganization that
was made to the Icon compiler.

\subsection{Reorganizing the Code}

After analyzing the functions that manipulate type information, those
functions that inspect, modify, or delete type bits were
isolated. These functions required modification so that they could
handle the packed type representation. In order to facilitate the
understanding of these changes, these functions and macros that
manipulate type vectors moved from \textfn{typinfer.c} to a new file
called \textfn{types.c}. The following macros were modified or moved
to \textfn{types.c}.

\goodbreak
\begin{iconcode}
NumInts(n\_bits)\\
ClrTyp (size, typ)\\
CpyTyp (nsize, src, dest)\\
MrgTyp (nsize, src, dest)\\
ChkMrgTyp(nsize, src, dest)\\
\end{iconcode}

\texttt{ClrTyp}, \texttt{CpyTyp}, \texttt{MrgTyp}, and
\texttt{ChkMrgTyp} were modified to handle the compact vectors while
NumInts moved for the sake of consistency. The functionality of these
macros has not changed.

The following functions were also modifed or moved to \textfn{types.c}.

\goodbreak
\begin{iconcode}
struct typinfo *alloc\_typ(unsigned int n\_types);\\
novalue set\_typ(struct typinfo *type, unsigned int bit);\\
novalue clr\_typ(struct typinfo *type, unsigned int bit);\\
int has\_type(struct typinfo *type, int typcd, int clear);\\
int other\_type(struct typinfo *type, int typcd);\\
int bitset(struct typinfo *type, int bit);\\
int is\_empty(struct typinfo *type);\\
novalue bitrange(int typcd, int *frst\_bit, int *last\_bit);\\
novalue typecd\_bits(int typcd, struct type *type);\\
\end{iconcode}


All the above functions required modification for the new type
representation except for \texttt{bitrange} and \texttt{typecd}.

\subsection{New Functions}

The following functions were added to support the new type
representation and were placed in \textfn{types.c}. A description of
the purpose of each function is provided after the prototypes.

\iconline{ unsigned int *alloc\_mem\_type(int unsigned int n\_ntypes) }

Allocates an actual bit vector large enough to hold \texttt{n\_types}
number of bits. The pointer to the \texttt{unsigned int} array is
returned.

\iconline{ novalue xfer\_packed\_types(struct typinfo *type) }

Transfers the types in the packed representation to the full length
bit vector in the same \texttt{struct typinfo} variable. It assumes
that the \texttt{bits} field of the \texttt{struct typinfo} is
valid. The transfer is done by finding the appropriate word in the
array where a specific bit is supposed to be and creating a mask that
is ANDed to that position in the array.

\iconline{ int xfer\_packed\_to\_bits(struct typinfo *src, struct typinfo *dest, int nsize) }

Transfers the types in the packed representation from \texttt{src} to
a full length bit vector, \texttt{dest}, of type \texttt{struct
typinfo} upto a certain type (bit) in the vector represented by
\texttt{nsize}.

\iconline{ novalue and\_bits\_to\_packed(struct typinfo *src, struct typinfo *dest, int nsize) }

Performs a bitwise AND on two type vectors. Appropriate measures
will be taken for both packed and full type representation.

\iconline{ unsigned int get\_bit\_vector(struct typinfo *src, int pos) }

Builds a slice (selected word) of a full length bit vector from a
compact type form.

\iconline{ novalue clr\_packed(struct typinfo *src, int nsize) }

Zeros out the bits of the packed representation.

\iconline{ novalue cpy\_packed\_to\_packed(struct typinfo *src, struct typinfo *dest, int nsize) }

Copies the packed vector from one variable to the packed
representation of another variable. That is, the source variable's
types are copied into the destination if the type is within the first
\texttt{nsize} types.

\iconline{ int mrg\_packed\_to\_packed(struct typinfo *src, struct typinfo *dest, int nsize) }

Merges two packed vectors into one. This performs a logical AND of
all types within the first \texttt{nsize} types.

\subsection{Other Changes}

Other significant changes had to accompany the switch over to the new
type representation. All pointer variables of type \texttt{unsigned
int} that referred to a type had to be changed to a pointer to type
\texttt{struct typinfo}. This included changes in the following
compiler source files: \textfn{cproto.h}, \textfn{csym.h},
\textfn{ctree.h}, and \textfn{typinfer.c}. Note that this also
includes function parameters. Additionally, there were functions that
had code embedded in them to manipulate the bits of a type vector
manually. In these places, the code required reworking either to
call the functions that encapsulated bit manipulations or rewriting in
order to take advantage of the compact types. These functions are
listed in the following list followed by a list of brief explanations
of the modifications.

\iconline{ novalue typinfer(void) }

Allocates a special variable with all the bits on. This required a
call to \texttt{alloc\_mem\_type} in order to allocate a full length
type vector. All the bits were then set to on.

\iconline{ struct store *alloc\_stor(int store\_sz, int n\_types) }

Allocates a store which includes type information. This required
changing the \texttt{alloc} call to allocate \texttt{struct typinfo}
instead of \texttt{unsigned int}.

\iconline{ struct symtyps *symtyps(int n\_syms) }

Allocates symbol tables. This also required changing the
\texttt{alloc} call to allocate \texttt{struct typinfo} instead of
\texttt{unsigned int}.

\iconline{ novalue typ\_deref(struct typinfo *src, struct typinfo *dest, int chk) }

Before the type dereferencing is performed the \texttt{src} was merged
with the \texttt{dest} parameters. This required checking for packed
or full type vectors and handling them appropriately. Also, if the
boundary between first class and intermediate types falls in the
middle of a word, those intermediate types on the boundary word are
zeroed out.

\iconline{ novalue abstr\_typ(struct il\_code *il, struct type *typ) }

In one of the cases of a \texttt{switch} statement two type vectors
are ANDed together. This requires placing a function call to
\texttt{and\_bits\_to\_packed} in place of the existing code.

\iconline{ int eval\_cnv(int type\_cd, int index, int def, int *cnv\_flags) }

This function determines if a type conversion on a type will
succeed. To do this, a type vector is ANDed with several different bit
masks. This required checking for packed or full bit vectors and
handling them appropriately. In the case of a packed vector, the
function \texttt{get\_vector} is called to build a word with the
appropriate type bits set if they fall in the selected word of the
type vector.

\iconline{ struct argtyps *get\_argtyp(void) }

Allocates an argument list. This required changing the
\texttt{alloc} call to allocate \texttt{struct typinfo} instead of
\texttt{unsigned int}.

\subsection{Results of Type Optimization}

After the new type representation was implemented, tests were run
again on \textit{Ctree}. The results showed a dramatic decrease in the
required amount of memory necessary for compilation. UTSA Iconc
required one third the amount of memory of the old compiler. The
program \textit{Freedom in the Galaxy} even compiled under this
optimization. Section 24.4 provides detailed results of the memory
usages for both \textit{Ctree} and \textit{Freedom in the Galaxy}.

\section{Optimizing the Generated Code}

The other area of optimization is the efficiency of the C code
generated by the Icon compiler. The optimizations undertaken were to
remove redundant calls to system functions, constant propagation, and
variable initialization. These optimizations were obvious from a
cursory examination of the C code generated. The goals of these
optimizations are to make the intermediate code as small as possible
and to speed up the resulting executable. First a brief summary of
the internal representation of the C code is provided. This is
necessary because most of these optimizations rely heavily on
analyzing the internal C code. Following this, the individual
optimizations are discussed in detail.

\subsection{Intermediate Code Representation}

This section briefly describes how the intermediate C code is
represented and generated internally by the Icon compiler.  The
majority of the functions that generate this internal representation
and print it to a file are contained in the following compiler source
files: \textfn{ccode.c}, \textfn{codegen.c}, and \textfn{inline.c}.

{\sffamily
How Code is Generated}

Once the source code is parsed and evaluated, the intermediate C code
needs to be generated and output to a file for compilation by the
native C compiler. First the compiler builds a syntax tree plus symbol
tables and other necessary structures. Then, the header file is
created. This includes standard definitions necessary for all Icon
programs and structures and variables specific to the program being
compiled. Next, the \texttt{proccode} function is called for each
function in the tree. This outputs the function definition and
variable in initialization code, and then steps through the syntax
tree and creates C code to represent the body of the function. After
all the code for the body of the current procedure is generated
internally, the code is then written to the file.

The internal C code is represented through a C structure called
\texttt{struct code} which is shown below.

\goodbreak
\begin{iconcode}
struct code \{\\
\>int cd\_id;\\
\>struct code *next;\\
\>struct code *prev;\\
\>union \ cd\_fld \ fld[1];\\
\};\\
\end{iconcode}


The \texttt{cd\_id} field is an identifier signaling what type of code
is held in this structure. This field may be set to one of the
following enumerated values. Each value corresponds to a type of code
that can be written to the intermediate C code. The table in Figure
24-4 contains the enumerated name along with its integer value and a
short description.

\begin{center}
\tablefirsthead{\hline
{\itshape Code Type} &
{\itshape Value} &
{\itshape Description}\\}
\tablehead{\hline
{\itshape Code Type} &
{\itshape Value} &
{\itshape Description}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|>{\texttt\bgroup}m{1in}<{\egroup}|m{0.5in}|m{2.5in}|}
\hline
C\_Null &
\raggedleft 0 &
 No code in this struct\\\hline
C\_CallSig &
\raggedleft 1 &
 Call a signal (function)\\\hline
 C\_RetSig &
\raggedleft 2 &
 Return a signal\\\hline
 C\_NamedVar &
\raggedleft 3 &
 Reference a variable\\\hline
 C\_Goto &
\raggedleft 4 &
 Goto statement\\\hline
 C\_Label &
\raggedleft 5 &
 Label statement\\\hline
 C\_Lit &
\raggedleft 6 &
 Literal value\\\hline
 C\_Resume &
\raggedleft 7 &
 Resume signal\\\hline
 C\_Continue &
\raggedleft 8 &
 Continue signal\\\hline
 C\_FallThru &
\raggedleft 9 &
 Fall through signal\\\hline
 C\_PFail &
\raggedleft 10 &
 Procedure failure\\\hline
 C\_PRet &
\raggedleft 11 &
 Procedure return\\\hline
 C\_PSusp &
\raggedleft 12 &
 Procedure suspend\\\hline
 C\_Break &
\raggedleft 13 &
 Break out of signal handling switch\\\hline
 C\_LBrack &
\raggedleft 14 &
 Start of a new C block\\\hline
 C\_RBrack &
\raggedleft 15 &
 End of a C block\\\hline
 C\_Create &
\raggedleft 16 &
 Call create() for a create expression\\\hline
 C\_If &
\raggedleft 17 &
 If statement\\\hline
 C\_SrcLoc &
\raggedleft 18 &
 Source file name\\\hline
 C\_CdAry &
\raggedleft 19 &
 Array of code pieces\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-4: Code Types
\par}


The \texttt{fld} field is important and is directly linked to what
type of code the \texttt{struct code} is defined as.  For example, if
a \texttt{struct code} is defined as \texttt{C\_If} then
\texttt{fld[0]} is a pointer to another \texttt{struct code} that
corresponds to the if portion of the statement, and \texttt{fld[1]} is
another pointer to a \texttt{struct code} representing the then
portion of the statement. In fact there are two macros for extracting
each pointer. These macros plus macros for all the other code types
are found in the \texttt{ccode.h} header file. However, there is one
special case that requires some explanation. If the \texttt{cd\_id} is
\texttt{C\_CdAry} then the \texttt{fld} element is an unspecified
length of \texttt{cd\_fld} unions. In this case all even indices into
the array are tags describing the contents of the following array
element. There is a special marker, \texttt{A\_End}, that signifies
the end of the array.

Figure{\color{red}\~{}{\textbackslash}ref\{fig:struct\_code\_assign\_full\}} shows
these field identifiers along with their corresponding fields for an
assignment statement. It is important to note that only when the
\texttt{cd\_id} is \texttt{C\_CdAry} will the field identifiers be
present. Figure 24-5 gives the possible values for these tags.

\begin{center}
\tablefirsthead{\hline
{\itshape Element Type} &
{\itshape Value} &
{\itshape Description}\\}
\tablehead{\hline
{\itshape Element Type} &
{\itshape Value} &
{\itshape Description}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{0.93935984in}|m{0.41775984in}|m{3.12266in}|}
\hline
 A\_Str &
\raggedleft 0 &
 Pointer to a string\\\hline
 A\_ValLoc &
\raggedleft 1 &
 Pointer to a struct val\_loc\\\hline
 A\_Intgr &
\raggedleft 2 &
 Integer value\\\hline
 A\_ProcCont &
\raggedleft 3 &
 Procedure continuation\\\hline
 A\_SBuf &
\raggedleft 4 &
 String buffer\\\hline
 A\_CBuf &
\raggedleft 5 &
 Cset buffer\\\hline
 A\_Ary &
\raggedleft 6 &
 Pointer to a subarray of struct code structures\\\hline
 A\_End &
\raggedleft 7 &
 Marker for end of array\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-5: Element Types
\par}

For the most part the \texttt{C\_CdAry} is used for miscellaneous code
that is not covered by the other 19 code types. Most simple
assignments fall into this category. The last two elements of a
\texttt{struct code}, \texttt{next} and \texttt{prev}, are links to
the next and previous \texttt{struct code} structures in the chain.


\bigskip

\begin{center}{\color{red} Missing figure}\end{center}
\bigskip

{\centering\selectlanguage{english}
Figure 24-6: Literal
\par}

\subsection{Redundant Function Calls}

An example of this type of optimization are several function calls
needed to handle certain run-time system activities in Icon that are
included in the generated C code. For example, throughout the code
Icon places a call to the macro \texttt{Poll()} which checks for
pending events such as window redraws. In some cases there is a call
to \texttt{Poll()} followed by an assignment and another call to
\texttt{Poll()} which is far too frequent. The placement of these
calls can be analyzed to determine when they are necessary.

{\sffamily
Analyzing Function Call Placement}

The solution to this problem entails analyzing where the calls to
\texttt{Poll()} were being placed. The \texttt{Poll()} macro is
inserted into the generated code by the function \texttt{setloc} which
is located in the file \texttt{ccode.c} of the compiler source. The
old method for determining when to insert a call to this function is
somewhat confusing. Also \texttt{setloc} does more than insert these
function calls so there was no change in the way it determined when to
put a call in. Instead, a call to \texttt{analyze\_poll} is made that
determines if it is safe to remove the previous occurrence of the
\texttt{Poll} function. To accomplish this, a global variable is kept,
called \texttt{lastpoll}, which is a pointer of type \texttt{struct
code}, and it is always assigned to the location of the last
\texttt{Poll} function. Of course, initially \texttt{lastpoll} is
\texttt{NULL}. The global variable is declared in
\texttt{ccode.c}. The prototypes for the two new functions are as
follows:

\iconline{ int analyze\_poll(void) }

This function analyzes the code between the last occurrence of the
\texttt{Poll()} macro and the current position. If there are no
function calls (\texttt{C\_CallSig}), return signals
(\texttt{C\_RetSig}), C code blocks (\texttt{C\_LBrack} or
\texttt{C\_RBrack}), return calls (\texttt{C\_PRet}), procedure
suspends (\texttt{C\_PSusp}), or break (\texttt{C\_Break}), then the
previous instance of \texttt{Poll} will be removed; otherwise, it will
be left in place.

The reason why the above code types are restricted is because they all
involve calling other functions. If it were known that these functions
were short and did not call other functions, then the call to
\texttt{Poll()} could be removed without worry; however, this kind of
detailed analysis is not performed and is inhibited by the fact that
some of these functions represented by \texttt{C\_CallSig} may be
library functions and these are linked at C compile time.

Also, regardless of whether the previous instance of a call to
\texttt{Poll()} is removed the new call to \texttt{Poll()} is added to
the code list and the \texttt{lastpoll} variable is updated.

\iconline{
novalue remove\_poll(void)
}


This function actually removes the call to \texttt{Poll()} by setting
the \texttt{cd\_id} field in the \texttt{struct code} structure to
\texttt{C\_Null}. It is important to note that the \texttt{struct
code} that represents the call to \texttt{Poll()} is not physically
deallocated from the list. Its \texttt{cd\_id} field is simply set
to \texttt{C\_Null} because removing it introduces side effects which
are either errors during C compilation or the misplacement of
\texttt{goto} labels which affects the flow of execution and
unpredictable results. This occurs because a \texttt{struct code}
of type \texttt{C\_Goto} may reference the removed node.

\subsection{Icon Literals and Constant Propagation}

Constant progagation was the second most difficult optimization to
implement next to the new type representation because the Icon
compiler generates a complex data structure that contains Icon values,
including literals. These Icon literals are assigned into this tended
descriptor table even though these values are constants. There are
several reasons to improve the representation of these constants.

First, by changing these complicated Icon literals to simple C
literals, the resulting executable code will be smaller. Secondly,
there is the issue of constant propagation. In many cases, an index
into the descriptor table is passed to a function or assigned to a
variable. The question that arises is whether the C compiler can
detect that the descriptor table value being passed is a constant that
can be propagated to all places where the descriptor table is used.
For example, the following code fragment is fairly common:

\begin{iconcode}
r\_frame.tend.d[4].dword = D\_Integer;\\
r\_frame.tend.d[4].vword.integr = 1;\\
irslt = sub(argp[0].vword.integr, r\_frame.tend.d[4].vword.integr);
\end{iconcode}

In this section of code, the structure
\texttt{r\_frame.tend.d[4].vword.integr} is assigned a value and then
immediately used. This code can be simplified to:

\iconline{
\> irslt = sub(argp[0].vword.integr, 1);
}


Note that the assignment of the literal into the descriptor table may
no longer be necessary; time savings on this initialization may be as
great as the savings for the simplified reference.

{\sffamily
Tended Descriptor Tables}


Most functions contain a tended descriptor table. This is an array of
descriptor structures which contain either an integer, pointer to a
string, pointer to a block, or a pointer to another descriptor
location. A named variable is assigned a specific index into the
descriptor table while temporary variables are assigned an index, but
other temporary variables can be assigned into the same cell many
times over. Named variables are all those that are explicitly used in
the Icon source code such as loop control variables, and temporary
variables are constants values (regardless of type). For example, in
the first Icon code example the value 2.4 is assigned its own location
into the descriptor table. The same thing holds true for the second
example. The string \texttt{{\textquotedbl}foo{\textquotedbl}} is
assigned its own location. Because both these values are only literals
in the Icon code, they are given temporary locations in the tended
desciptor table that may be used over again.

\begin{iconcode}
\>   if (x\_val = 2.4) then \\
\> \>   do\_something(x\_val) \\
\>   ... \\
\>   ... \\
\>   if (str\_val == "foo") then \\
\> \>   do\_something(str\_val)
\end{iconcode}


For example, if the constant \texttt{2.4} is not used after the second
code fragment then \texttt{{\textquotedbl}foo{\textquotedbl}} may be
assigned into the location previously occupied by \texttt{2.4}.

{\sffamily
Analyzing Literal Assignments}


Several new functions were introduced in order to analyze all
constants and their use. Inside the function \texttt{proccode} before
the internal C code is written to a file, a call to
\texttt{analyze\_literals} and \texttt{propagate\_literals} is made
which does the propagation. The \texttt{analyze\_literals} function
builds a table which contains information such as the scope of a
descriptor entry, whether it is safe to propagate a literal, and the
literal value. The table structure is given below.

\begin{iconcode}
struct lit\_tbl \{ \\
\> int \ \ \ modified; \\
\> int \ \ \ index; \\
\> int \ \ \ safe; \\
\> struct code *initial; \\
\> struct code *end; \\
\> struct val\_loc *vloc; \\
\> struct centry \ *csym; \\
\> struct lit\_tbl *prev; \\
\> struct lit\_tbl *next; \\
\};
\end{iconcode}

The field \texttt{modified} is a flag which can be set to one of the
enumerated types in Figure 24-7.

\begin{center}
\tablefirsthead{\hline
{\itshape Name} &
{\itshape Value} &
{\itshape Description}\\}
\tablehead{\hline
{\itshape Name} &
{\itshape Value} &
{\itshape Description}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.4302598in}|m{0.41155985in}|m{3.7115598in}|}
\hline
{\ttfamily NO\_LIMIT} &
\raggedleft 0 &
 Descriptor never changes\\\hline
{\ttfamily LIMITED} &
\raggedleft 1 &
 Descriptor value does change, propagate any type\\\hline
{\ttfamily LIMITED\_TO\_INT} &
\raggedleft 2 &
 Descriptor value does change, propagate only if integer\\\hline
{\ttfamily NO\_TOUCH} &
\raggedleft 3 &
 Descriptor value should not be propagated\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-7: Modify Flags
\par}


The \texttt{NO\_LIMIT} value refers to those descriptor locations that
always contain the same constant. That is, no other value shares the
same descriptor location, and it may be propagated freely without
conflicts. The \texttt{LIMITED} value refers to those descriptor
locations that are either reused at some point or are modified is some
way. The value \texttt{LIMITED\_TO\_INT} is similar except that
special care must be taken when propagating this constant. For
example, a constant such as a string should not be propagated
everywhere an interger may be propagated.

Lastly, the value \texttt{NO\_TOUCH} refers to descriptor locations
that should not be propagated. These descriptor locations often
contain loop control variables which are marked as temporary but
should under no circumstances be replaced with their initial
values. For example, the first code fragment shows unoptimized code,
and the second fragment is the same code but with constants
propagated. Descriptor location 6 should not be touched because it
serves as a loop control variable while the use of location 7 may be
replaced with its constant value 10 even though the same location is
assigned a new value later on after label \texttt{L9}.

\begin{iconcode}
\>   r\_frame.tend.d[6].dword = D\_Integer; \\
\>   r\_frame.tend.d[6].vword.integr = 1; \\
\>   r\_frame.tend.d[7].dword = D\_Integer; \\
\>   r\_frame.tend.d[7].vword.integr = 10; \\
L8: \\
\>   if (!(r\_frame.tend.d[6].vword.integr {\textless}= \\
\> \> \> \> \> r\_frame.tend.d[7].vword.integr) ) \\
\>  goto L9; \\
\>   ... \\
\>   ++r\_frame.tend.d[6].vword.integr; \\
\>   goto L8; \\
L9: \\
\>   r\_frame.tend.d[7].dword = D\_Integer; \\
\>   r\_frame.tend.d[7].vword.integr = 7; \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\
\>   r\_frame.tend.d[6].dword = D\_Integer; \\
\>   r\_frame.tend.d[6].vword.integr = 1; \\
L8: \\
\>   if (!(r\_frame.tend.d[6].vword.integr {\textless}= 10) ) \\
\> \>    goto L9; \\
\>   ... \\
\>   ++r\_frame.tend.d[6].vword.integr; \\
\>   goto L8; \\
L9: \\
\>   r\_frame.tend.d[7].dword = D\_Integer; \\
\>   r\_frame.tend.d[7].vword.integr = 7;
\end{iconcode}


The field \texttt{index} is the index into the descriptor table for
each constant.


The field \texttt{safe} refers to whether or not it is safe to modify
the \texttt{end} field. This field refers to the point in the
intermediate code beyond which it is no longer safe to propagate this
value. The \texttt{end} field is sometimes modified when inserting a
new entry into the literal table. This is described in detail under
the \texttt{tbl\_add} function presented shortly.


The fields \texttt{initial} and \texttt{end} refer to the scope where
it is safe to propagate the current literal between. If \texttt{end}
is \texttt{NULL} then it is safe to propagate to the end of the
function.


The fields \texttt{vloc} and \texttt{csym} are pointers to either a
\texttt{struct val\_loc} or a \texttt{struct centry} which contain the
constant value of the current descriptor. The \texttt{struct centry}
member points to the corresponding location in the global symbol table
of constant values maintained by the Icon compiler.

The fields \texttt{prev} and \texttt{next} are necessary to make the
table doubly linked.

Also, it should be noted that the number of entries in the literal
table is fairly small. During compilation of \textit{Ctree}, the
largest literal table used contained 15 entries.

The analysis phase consists of stepping through the \texttt{struct
code} chain for each function looking for each instance of a
literal. Figure 24-8 shows how a literal is contained within a
\texttt{struct code} structure. At this point, a new entry into the
literal table is created that keeps track of where in the code the
literal is assigned into the descriptor table and a pointer to the
\texttt{struct centry} structure where the literal value is kept.
This phase also attempts to find the point at which descriptor entries
are assigned new values. Thus a scope is defined which the constant
may only be propagated between.


\bigskip

{\centering\selectlanguage{english}
  {\color{red}Missing Figure}\\
Figure 24-8: Literal
\par}


Once the analysis is complete and the literal table is built then the
function \texttt{propagate\_literals} is called which goes through
each entry in the literal table and examines the code beginning at the
\texttt{initial} field until the \texttt{struct code} referenced by
the \texttt{end} field is encountered. If a \texttt{struct code} is
found that references the descriptor containing the current literal
then that reference is replaced by the literal itself. Figure 24-6
illustrates a fragment of code that does an assignment, and Figure
24-9 shows the same fragment with the second descriptor replaced with
its literal (assuming that descriptor location 8 was previously
initialized to 27). It is important to note that only the
\texttt{struct val\_loc} on the right side of the equal sign will be
replaced by its literal.


\bigskip

{\centering\selectlanguage{english}
  {\color{red}Missing Figure}\\
Figure 24-9: Assignment
\par}

\subsection{New Functions}

The following functions were created to support the contant
propagation optimization. All these functions are placed in the
compiler source file \textfn{ccode.c}. Each function used in the
constant propagation is prototyped and described below.

\iconline{ struct lit\_tbl *alc\_tbl(void) }

This function allocates a \texttt{struct lit\_tbl} entry that contains
information about a literal and its usage. It first checks a global
pointer called \texttt{free\_lit\_tbl} to see if there are any free
table structures that may be reused. If there are no free structures
in this list then a new structure is allocated. Lastly, the fields are
initialized to predefined values.

\iconline{ novalue free\_tbl(void) }

This function frees the memory used for the current table by attaching
the current table to the list of free table structures
(\texttt{free\_lit\_tbl}).

\iconline{ novalue tbl\_add(struct lit\_tbl *add) }

This function adds a new \texttt{struct lit\_tbl} structure into the current
table. The insertion is to the end of the table plus it checks for the
previous use of the descriptor location used in the element being
added. For the previous use of the same element, that location's
\texttt{end} pointer is set to the initial pointer of the element
being added. In essence, this defines a scope for each descriptor
location. Once \texttt{end} is set for the first time, it should not
be changed later.

\iconline{ int substr(const char *str, const char *sub) }

This function is used to scan strings for logical operators
(\texttt{==}, \texttt{!=}, \texttt{{\textgreater}=},
\texttt{{\textless}=}, etc). If the string represented by \texttt{sub}
is found in \texttt{str} then \texttt{TRUE} is returned. It is
necessary to identify these operators so a string is not propagated as
an operand to one of these operators which is not valid C syntax.

\iconline{ int instr(const char *str, int chr) }

This function is used to determine if a string contains an assignment
operator. \ This function will return \texttt{TRUE} if the string
\texttt{str} contains any type of assignment (\texttt{=}, \texttt{+=},
\texttt{{}-=}, \texttt{*=}, \texttt{/=}, or \texttt{\%=}).

\iconline{ novalue invalidate(struct val\_loc *v, struct code *end, int code) }


This function sets values for an element in the literal table. For all
literal table entries that point to the \texttt{struct val\_loc}
represented by \texttt{v} the \texttt{end} field is set to
\texttt{end} with the \texttt{modified} field set to
\texttt{code}. \texttt{code} can be one of the following enumerated
values: \texttt{NO\_LIMIT}, \texttt{LIMITED},
\texttt{LIMITED\_TO\_INT}, or \texttt{NO\_TOUCH}.

\iconline{ novalue analyze\_literals(struct code *start, struct code *top, int lvl) }


This function steps through the \texttt{struct code} list for each
function, building up a literal table, and analyzing the scope between
which each literal can be safely propagated. It checks for loop
control variables, when and if the value of a constant descriptor
location changes, and checks to see if a descriptor location is passed
by reference to any functions.

\iconline{ novalue propagate\_literals(void) }

This function steps through each entry in the literal table and begins
to replace occurences of the descriptor location with the literal
between the \texttt{struct code} structures from the \texttt{initial}
field to the \texttt{end} field.  The function \texttt{eval\_code} is
called to do the actual propagation.

\iconline{ int eval\_code(struct code *cd, struct lit\_tbl *cur) }

This function first checks to see if the descriptor index of the code
currently being examined matches that of the current literal table
entry. If the current descriptor is accessed as an integer or a string
then the descriptor is replaced with the literal value. Also, the
\texttt{modified} is checked to see if there are any restrictions on
replacement. The table in Figure 24-10 lists the restrictions for
each possible value of \texttt{modified}.

\begin{center}
\tablefirsthead{\hline
{\itshape Name} &
{\itshape Replacement Restrictions}\\}
\tablehead{\hline
{\itshape Name} &
{\itshape Replacement Restrictions}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.4670599in}|m{3.2670598in}|}
\hline
{\ttfamily NO\_LIMIT} &
 Always replace\\\hline
{\ttfamily LIMITED} &
 Always replace within \texttt{initial} and \texttt{end}\\\hline
{\ttfamily LIMITED\_TO\_INT} &
 Only replace if used as int, also limited by scope\\\hline
{\ttfamily NO\_TOUCH} &
 Never replace\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-10: Replacement Policy
\par}


The actual replacement of a descriptor reference to a literal is
accomplished by setting the current index into the \texttt{fld} array
to the \texttt{A\_Str} type and allocating a string where the literal
is copied into. Figure 24-6 and Figure 24-9 illustrate an occurrence
of this.

\subsection{Variable Initialization}

Another issue is the initialization of the descriptor tables in each C
function that is generated by the Icon compiler.  Many of the
generated functions contain a loop that initializes all the entries of
the local descriptor table to the null descriptor. This is rather
cumbersome and generates a great deal of overhead.

{\sffamily
Eliminating Dead Code}


The first optimization to the variable initialization was to eliminate
{\textasciigrave}{\textasciigrave}dead'{}' code, which is code that is
never executed. In some cases the loops that initialize the
descriptor tables resembled this:

\goodbreak
\begin{iconcode}
for (i = 0; i < 0; ++i)\\
\>r\_frame.tend.d[i] = nulldesc;\\
\end{iconcode}


This code is generated for Icon library functions in the function
\texttt{outerfnc} located in \textfn{codegen.c}. There is a separate
function that outputs similar code for user written functions which
does check to see if the loop will ever execute. Both functions
contain a variable \texttt{ntend} which hold the number of descriptor
entries. A simple check for equality with zero was added.

\subsection{Loop Unrolling}

Every user function initializes all tended descriptor entries to the
value of the null descriptor \texttt{nulldesc} at the beginning of the
function. It is a simple one-line \texttt{for} loop similar to the
following code fragment.

\goodbreak
\begin{iconcode}
for (i = 0; i < 3; ++i)\\
\>r\_frame.tend.d[i] = nulldesc;\\
\end{iconcode}


Also, upon examining the C code generated from several programs, the
number of descriptor entries per procedure rarely exceeds ten. Because
this is a relatively small number, these loops can be unrolled into a
series of assignments, and the loop may be removed. The following code
is the above loop unrolled.

\goodbreak
\begin{iconcode}
r\_frame.tend.d[0] = nulldesc;\\
r\_frame.tend.d[1] = nulldesc;\\
r\_frame.tend.d[2] = nulldesc;\\
\end{iconcode}

While this will increase the size of the generated code, the loop
overhead is eliminated. There is a limit placed on the number of loop
iterations that will be unrolled which is defined in
\textfn{define.h}. Currently, this value, \texttt{LoopThreshold}, is
set to 6. Because this number and the number of descriptor table
entries is small, the number of unrolled elements is reasonable, and
the code size is not greatly affected.


The code that unrolls these loops is in the function \texttt{outerfnc}
in the file \textfn{codegen.c}. Because this change is only several
lines, the code that implements loop unrolling is included below.

\goodbreak
\begin{iconcode}
\#ifdef OptimizeLoop\\
if (ntend > 0) \ \ \ \ \ \ \ \ \ \ /* Check for dead code */\\
\>for (i=0; i < ntend ;i++)\\
\>\>fprintf(codefile,\\
\>\>\>\>\ \ " \ \ r\_frame.tend.d[\%d] = nulldesc; {\textbackslash}n",i);\\
\#else\\
fprintf(codefile, "for (i=0; i < \%d ;i++) {\textbackslash}n", ntend);\\
fprintf(codefile, " \ \ f\_frame.tend.d[i] = nulldesc;{\textbackslash}n;");\\
\#endif\\
\end{iconcode}

\subsection{Results of Code Generation Optimizations}

Several tests were run to determine whether the code generation
optimizations were effective. These optimizations were performed in
hopes of improving the execution speed of the compiled program,
reducing the size of the intermediate code and the resulting
executable, and the compilation time. A brief description of the
results follows; however, a more detailed analysis of the
optimizations is given in Chapter 16.


Overall, the optimizations improved the execution speed by a modest
amount. The improvement is roughly between 6-8.25\%.  While this is
not a great as was hoped, it still is an improvement. The code size of
both the intermediate code and the generated executable are
suprisingly smaller. The loop unrolling seemed to be offset by the
constant progagation which eliminated unnecessary assigments and
references. The size of the executables were reduced by approximately
4-8\% for large programs, but there was no change in executable size
for small programs (20 lines). The size of the generated C file was
consistently around 3\% smaller than before the optimizations.


Also, on average around half of all calls to \texttt{Poll} were
removed, and in one case, two thirds were eliminated.  The largest
improvement was to compilation time. The optimizations improved
compile time by 24-31\% on large programs and 13\% on small programs;
however, it should be noted that all of the tests for this section
were performed with all the optimizations on, including the type
representation optimization.

\section{Results}

This chapter presents detailed information on the results of each
optimization discussed in this paper. The first section discusses the
improvements in memory usage resulting from the type representation
optimizations while the second sections presents the results from
removing redundant function calls, unrolling loops, removing dead
code, and propagating literals.

\subsection{Type Representation}

Tests were performed on \textit{Ctree} and \textit{Freedom in the
Galaxy} to determine the new memory requirements of UTSA Iconc. These
tests were run with only the type representation optimizations and no
other optimizations that were covered in Chapter 15. The results show a
substantial decrease in the memory required to compile the
program. For \textit{Ctree}, there were 156,992 packed type structures
allocated which is the total number of all type vectors from the first
test. Once the packed structure was allocated only 11,653 needed an
actual first class vector allocated.  Of the intermediate class, only
5,172 full-size vectors needed to be allocated. However, all 121 of
the database class variables needed the full sized vector. Overall,
the total memory usage for type representation is 2.17 megabytes which
is 35\% of the memory required by the old type representation. The
results are summarized in Figure 24-11.

\begin{center}
\tablefirsthead{\hline
{\itshape Vector Type} &
 Number of Types &
 Number Allocated &
 Required Memory (MB)\\}
\tablehead{\hline
{\itshape Vector Type} &
 Number of Types &
 Number Allocated &
 Required Memory (MB)\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.2163599in}|m{1.1969599in}|m{1.2538599in}|m{1.6636599in}|}
\hline
 packed class &
\raggedleft 5 &
\raggedleft 156992 &
\raggedleft\arraybslash 1.25\\\hline
 first class &
\raggedleft 209 &
\raggedleft 11653 &
\raggedleft\arraybslash 0.3\\\hline
 intermediate class &
\raggedleft 1012 &
\raggedleft 5172 &
\raggedleft\arraybslash 0.6\\\hline
 database class &
\raggedleft 1369 &
\raggedleft 121 &
\raggedleft\arraybslash 0.02\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-11: Memory Usage (\textit{Ctree})
\par}


Unfortunately, the improvement in memory usage was not great enough
for \textit{Freedom in the Galaxy} to compile on the same machine that
the tests on \textit{Ctree} were run; however, the program did compile
on a Sparc 10 with 128MB of memory with no one else logged on at the
time. The Figure 24-12 contains the memory requirements for each of
the classes of vectors.

\begin{center}
\tablefirsthead{\hline
 Vector Type &
 Number of Types &
 Number Allocated &
 Required Memory (MB)\\}
\tablehead{\hline
 Vector Type &
 Number of Types &
 Number Allocated &
 Required Memory (MB)\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.2288599in}|m{1.2170599in}|m{1.2427598in}|m{1.6538599in}|}
\hline
 packed class &
\raggedleft 5 &
\raggedleft 4294822 &
\raggedleft\arraybslash 34.36\\\hline
 first class &
\raggedleft 1425 &
\raggedleft 119468 &
\raggedleft\arraybslash 21.5\\\hline
 intermediate class &
\raggedleft 8508 &
\raggedleft 24349 &
\raggedleft\arraybslash 25.91\\\hline
 database class &
\raggedleft 12591 &
\raggedleft 7 &
\raggedleft\arraybslash 0.01\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-12: Memory Usage (\textit{Freedom in the Galaxy})
\par}


Even with the optimization, \textit{Freedom in the Galaxy} requires
over 81 megabytes of memory for the type inferencing alone. Because
Freedom in the Galaxy could not be compiled before the type
optimization, there are no numbers to compare these with. However,
considering that the type optimization reduce the memory requirements
for Ctree by one third, then a good estimate for the memory
requirements would be around 240 megabytes!

While the new type representation drastically reduces the amount of
memory used during compilation, it still uses too much memory to be of
use when compiling large programs on anything but an expensive
workstation with a substantial amount of memory. However, UTSA Iconc
still offers the user the advantage of compiled code, and the new type
representation makes UTSA Iconc practical on many programs that could
not be compiled because of memory requirements of the old Icon
compiler.

\subsection{Code Generation}

This section details the results of the code generation optimizations
in the area of execution speed, code size, and compilation time. These
tests were run on several programs. The first program,
\textit{Beards}, generates production grammars, non-terminals,
terminals, and epsilon sets from an input grammar. The second program,
\textit{Yhcheng}, is a line editor similar to \texttt{ed} which also
has revision control capabilities. For the code size and compilation
time tests, two other programs, \textit{Ctree} and \textit{Sphere},
were used for tests. \textit{Beards}, \textit{Yhcheng}, and
\textit{Ctree} are all large programs while \textit{Sphere} is
included because it is a very small program (less than 25 lines).  All
timings performed used the Unix or Linux \texttt{time} utility.  Also
note that these timings were performed with all optimizations turned
on including the type representation optimization.

{\sffamily
Execution Speed}

Each program was run 10 times with sample input and averages were
computed. Figure 24-13 summarizes the execution times for
\textit{Beards} and \textit{Yhcheng}.

\begin{center}
\tablefirsthead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape User} &
{\itshape System} &
{\itshape Elapsed}\\}
\tablehead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape User} &
{\itshape System} &
{\itshape Elapsed}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|}
\hline
~
 &
 Optimized &
\raggedleft 0.5 &
\raggedleft 0.12 &
\raggedleft\arraybslash 00:01.17\\\hline
 Beards &
 Unoptimized &
\raggedleft 0.52 &
\raggedleft 0.13 &
\raggedleft\arraybslash 00:01.27\\\hline
~
 &
 Improvement &
\raggedleft 4.97\% &
\raggedleft 9.09\% &
\raggedleft\arraybslash 8.25\%\\\hline
~
 &
 Optimized &
\raggedleft 0.59 &
\raggedleft 1.11 &
\raggedleft\arraybslash 00:01.99\\\hline
 Yhcheng &
 Unoptimized &
\raggedleft 0.62 &
\raggedleft 1.27 &
\raggedleft\arraybslash 00:02.14\\\hline
~
 &
 Improvement &
\raggedleft 4.21\% &
\raggedleft 12.91\% &
\raggedleft\arraybslash 6.79\%\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-13: Execution Times
\par}

{\sffamily
Code Size}

Tests were run on the same two programs to determine if there was an
improvement in either the intermediate code size or the size of the
resulting executable. Figure 24-14 displays the code sizes for
\textit{Beards}, \textit{Yhcheng}, \textit{Ctree}, and
\textit{Sphere}. The first three programs are large (500-1800 lines)
while \textit{Sphere} is small (20 lines).

\begin{center}
\tablefirsthead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape C File} &
{\itshape H File} &
{\itshape Executable}\\}
\tablehead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape C File} &
{\itshape H File} &
{\itshape Executable}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|m{1.1212599in}|}
\hline
~
 &
 Optimized &
\raggedleft 246159 &
\raggedleft 12967 &
\raggedleft\arraybslash 204800\\\hline
 Beards &
 Unoptimized &
\raggedleft 252041 &
\raggedleft 12967 &
\raggedleft\arraybslash 212992\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 2.33\%} &
\raggedleft{\itshape 0.00\%} &
\raggedleft\arraybslash{\itshape 3.85\%}\\\hline
~
 &
 Optimized &
\raggedleft 554014 &
\raggedleft 46168 &
\raggedleft\arraybslash 294912\\\hline
 Yhcheng &
 Unoptimized &
\raggedleft 568118 &
\raggedleft 46168 &
\raggedleft\arraybslash 319488\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 2.48\%} &
\raggedleft{\itshape 0.00\%} &
\raggedleft\arraybslash{\itshape 7.70\%}\\\hline
~
 &
 Optimized &
\raggedleft 290536 &
\raggedleft 61545 &
\raggedleft\arraybslash 225280\\\hline
 Ctree &
 Unoptimized &
\raggedleft 298813 &
\raggedleft 61545 &
\raggedleft\arraybslash 237568\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 2.77\%} &
\raggedleft{\itshape 0.00\%} &
\raggedleft\arraybslash{\itshape 5.17\%}\\\hline
~
 &
 Optimized &
\raggedleft 82289 &
\raggedleft 49755 &
\raggedleft\arraybslash 159744\\\hline
 Sphere &
 Unoptimized &
\raggedleft 84972 &
\raggedleft 49755 &
\raggedleft\arraybslash 159744\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 3.16\%} &
\raggedleft{\itshape 0.00\%} &
\raggedleft\arraybslash{\itshape 0.00\%}\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-14: Code Sizes
\par}


Much of the reduction in code size can be attributed to the removal of
redundant calls to \texttt{Poll}, and it is this reduction that
offsets the loop unrolling. Improvements on \textit{Beards},
\textit{Yhcheng}, and \textit{Sphere} show that almost one half of all
calls to \texttt{Poll} were eliminated; however, \textit{Ctree} shows
almost a two thirds reduction. Figure 24-15 shows the number of calls
to \texttt{Poll} for each program before and after the optimization.

\begin{center}
\tablefirsthead{\hline
{\itshape Test Program} &
 No. Before &
 No. After\\}
\tablehead{\hline
{\itshape Test Program} &
 No. Before &
 No. After\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{0.9406598in}|m{0.76435983in}|m{0.6712598in}|}
\hline
 Beards &
\raggedleft 810 &
\raggedleft\arraybslash 481\\\hline
 Yhcheng &
\raggedleft 2144 &
\raggedleft\arraybslash 1135\\\hline
 Ctree &
\raggedleft 745 &
\raggedleft\arraybslash 293\\\hline
 Sphere &
\raggedleft 40 &
\raggedleft\arraybslash 22\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-15: Number of Redundant Functions Removed
\par}

{\sffamily
Compilation Time}

Lastly, the compilation times for the sample programs are given. Each
program was compiled five times with the results averaged. Again,
results for the \textit{Beards}, \textit{Yhcheng}, \textit{Ctree}, and
\textit{Sphere} are in Figure 24-16.

\begin{center}
\tablefirsthead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape User} &
{\itshape System} &
{\itshape Elapsed}\\}
\tablehead{\hline
{\itshape Program} &
{\itshape Version} &
{\itshape User} &
{\itshape System} &
{\itshape Elapsed}\\}
\tabletail{}
\tablelasttail{}
\begin{xtabular}{|m{0.6288598in}|m{0.9636598in}|m{0.5997598in}|m{0.54205984in}|m{0.6420598in}|}
\hline
~
 &
 Optimized &
\raggedleft 43.57 &
\raggedleft 1.77 &
\raggedleft\arraybslash 00:47.40\\\hline
 Beards &
 Unoptimized &
\raggedleft 60.93 &
\raggedleft 1.65 &
\raggedleft\arraybslash 01:02.93\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 28.49\%} &
\raggedleft{\itshape {}-7.27\%} &
\raggedleft\arraybslash{\itshape 24.68\%}\\\hline
~
 &
 Optimized &
\raggedleft 116.97 &
\raggedleft 2.76 &
\raggedleft\arraybslash 02:04.14\\\hline
 Yhcheng &
 Unoptimized &
\raggedleft 163.37 &
\raggedleft 2.86 &
\raggedleft\arraybslash 02:49.71\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 28.40\%} &
\raggedleft{\itshape 3.50\%} &
\raggedleft\arraybslash{\itshape 26.85\%}\\\hline
~
 &
 Optimized &
\raggedleft 65.26 &
\raggedleft 2.54 &
\raggedleft\arraybslash 01:13.44\\\hline
 Ctree &
 Unoptimized &
\raggedleft 92.25 &
\raggedleft 2.88 &
\raggedleft\arraybslash 01:47.44\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 29.26\%} &
\raggedleft{\itshape 11.81\%} &
\raggedleft\arraybslash{\itshape 31.65\%}\\\hline
~
 &
 Optimized &
\raggedleft 11.98 &
\raggedleft 1.83 &
\raggedleft\arraybslash 00:16.36\\\hline
 Sphere &
 Unoptimized &
\raggedleft 13.62 &
\raggedleft 2.22 &
\raggedleft\arraybslash 00:18.85\\\hline
~
 &
 Improvement &
\raggedleft{\itshape 12.04\%} &
\raggedleft{\itshape 17.57\%} &
\raggedleft\arraybslash{\itshape 13.21\%}\\\hline
\end{xtabular}
\end{center}
{\centering\selectlanguage{english}
Figure 24-16: Compile Times
\par}

\subsection{Analysis of Intermediate Code Optimizations}

The gains in execution speed and code size were modest but not
startling. For the most part, improvement was less than 10\%.
However, the results for compilation time are more promising. The
speedup was between 24\% and 31\% for large programs, which is between
a 15 and 45 second improvement.

The eliminated functions calls most likely have a negligible effect on
execution speed but greatly contributed to the reduction in code
size. For example, on a large program like \textit{Yhcheng} which
contained more than 18,600 lines of C code, approximately 450
redundant calls were removed. It was not expected that eliminating
{\textasciigrave}{\textasciigrave}dead'{}' initialization loop would
have much effect on execution speed. Constant propagation and loop
unrolling probably accounted for the improved execution
times. However, more of an improvement was expected from the constant
propagation optimization. Two possible explanations could be that the
native C compiler is able to reduce the complex structure lookup to
its literal value or that the compiler has so much other baggage
slowing down execution that the constant propagation improvement was
not enough to make a great difference. The second explanation seems
more likely.

The size of the intermediate code and executable code were also
modestly improved. The elimination of redundant function calls offset
the addition of code due to loop unrolling. Also, eliminating
unnecessary initializations for literals that were propagated
contributed to the smaller code sizes. It is important to note that as
it is, the compiler generates an enormous amount of code for procedure
continuations and suspensions so that 25-30\% of the intermediate code
are these functions and the rest is user code.

Lastly, the speed of compilation was a pleasant surprise; however, I
do believe that this improvement is due to the type inferencing
optimization because the current optimizations being discussed only
add extra logic to improve the generated code. Another significant
factor is that less memory is being used by the type inferencing
system, which therefore causes less access to virtual memory. I should
note that all the tests were run with that optimization on, and the
improvement to type inferencing simplifies the type system in many
ways. To determine if a specific bit is set, the old system had to
create a mask and find the appropriate index into a long bit
vector. The new system requires a single comparison in the case of the
five builtin types.

{\sffamily
Conclusion}

All of the optimizations discussed in this chapter have been
implemented. Some of the optimizations performed extremely well while
others did not have much effect. The type representation change
provided a substantial improvement on the memory usage required by the
type inferencing system. As was stated early, the compiler still uses
too much memory to be of much use to the average Icon programmer but
is much better suited to offering the added speedup of compiled code
when occasionally necessary.

The intermediate code optimizations were really just the tip of the
iceberg of all the possible improvements to this area. The removal of
redundant calls to system calls was a small improvement. Literal
propagation was probably the most significant improvement along with
loop unrolling. Further optimizations in this area are likely to yield
the best improvements to performance.

\subsection{Future Optimizations}

After studying the generated code, several other optimizations were
identified that may offer additional improvements to both the speed of
execution and the size of the intermediate and executable code. The
next few paragraphs describe additional optimizations and are
organized in the order of the easiest to hardest to implement.

\liststyleLxxxvi
\begin{enumerate}
\item 
For the unrolled descriptor initializations change the indexing array to pointer arithmetic which is faster. For example
the following code fragment is modified as follows: 
\end{enumerate}
\goodbreak
\begin{iconcode}
r\_frame.tend.d[0] = nulldesc;\\
r\_frame.tend.d[1] = nulldesc;\\
r\_frame.tend.d[2] = nulldesc;\\
\end{iconcode}
\goodbreak
\makebox[0.5\textwidth]{\hrulefill}
\begin{iconcode}
register dptr p;\\
p = r\_frame.tend.d;\\
(p++)->dword = nulldesc;\\
(p++)->dword = nulldesc;\\
\end{iconcode}

\liststyleLxxxvii
\begin{enumerate}
\item 
Analyze the logic of loops and also unroll smaller ones. For example,
the following loop appears at the beginning of most functions.
\end{enumerate}
\goodbreak
\begin{iconcode}
for (i = 0; i < r\_nargs ; ++i)\\
\>deref(\&r\_args[i], \&r\_frame.tend.d[i + 0]);\\
for(i = r\_nargs; i < 2 ; ++i)\\
\>r\_frame.tend.d[i + 0] = nulldesc;\\
\end{iconcode}


In this case \texttt{r\_nargs} cannot be greater than two because it
was earlier declared to have only two entries. It would be necessary
to guarantee that \texttt{r\_nargs} can never be more than two, but if
it is certain that there are exactly two elements then we can write
the initialization loop as follows:

\goodbreak
\begin{iconcode}
if(r\_nargs > 0) \{\\
\>deref(\&r\_args[0], \&r\_frame.tend.d[0]);\\
\>if (r\_nargs > 1)\\
\>\>deref(\&r\_args[1], \&r\_frame.tend.d[1]);\\
\>else\\
\>\>tend.d[1].dword = D\_Null;\\
\>\}\\
else\\
\>tend.d[0].dword = D\_Null;\\
\end{iconcode}


This optimization could lead to a gain in execution speed. For
example, if the unrolling is performed on descriptors with array sizes
of one or two, approximately 40\% of these loops would be unrolled.

\liststyleLxxxviii
\begin{enumerate}

\item An easy and obvious solution would be to simplify expressions like
\texttt{i + 0} which commonly occur. This will not improve execution
time because the C compiler will catch this, but by removing it before
writing the statement to the intermediate file, the compile time of
the C compiler will be improved.

\item Another easy optimization would be to shorten variable
names. This causes a penalty by having to write long names such as
\texttt{r\_frame.tend.d} to file and then having the C compiler read
it back in. This could be changed to \texttt{r\_f.t.d}. While this
makes the intermediate C code hard to read, the intermediate code is
not meant to be inspected by the user and will result in faster
compilations.

\item For the initialization loops present in all functions, remove the
initialization of the loop control variable when unnecessary. Consider
the following loop:
\end{enumerate}
\goodbreak
\begin{iconcode}
for (i = 0; i < r\_nargs ; ++i)\\
\>deref(\&r\_args[i], \&r\_frame.tend.d[i + 0]);\\
for(i = r\_nargs; i < 2 ; ++i)\\
\>r\_frame.tend.d[i + 0] = nulldesc;\\
\end{iconcode}


The variable \texttt{i} in the second loop does not need to be
initialized since it is already at the value that it is supposed to be
for the second loop. The next fragment of code illustrates this change.

\goodbreak
\begin{iconcode}
for (i = 0; i < r\_nargs ; ++i)\\
\>deref(\&r\_args[i], \&r\_frame.tend.d[i + 0]);\\
for( ; i < 2 ; ++i)\\
\>r\_frame.tend.d[i + 0] = nulldesc;\\
\end{iconcode}


While this change is very easy, it is questionable whether this will
provide noticeable improvement in execution except in large programs
where these loops are very common.

\liststyleLxxxix
\begin{enumerate}
\item 
\ Assignments of the \texttt{r\_frame.tend.d} structures may be simplified. Consider the following assignment:
\end{enumerate}
\goodbreak
\begin{iconcode}
r\_frame.tend.d[2] /* i */.vword.integr =\\
\>r\_frame.tend.d[4].vword.integr;\\
r\_frame.tend.d[2] /* i */.dword = D\_Integer;\\
\end{iconcode}


This could be changed into a single assignment as follows:

\iconline{ \ \ r\_frame.tend.d[2] = r\_frame.tend.d[4]; }


This optimization would require more work than the previously
described ones. Each \texttt{struct val\_loc} structure would have
to be examined, including the context in which it is used in order to
catch assignments such as this; however, these assignments are very
common and could lead to substantial gains in execution speed.

\liststyleLxl
\begin{enumerate}
\item 
\ Similarly, perform the same simplified descriptor assignment on global descriptor locations. A method needs to be
created for changing global assignments such as:
\end{enumerate}
\goodbreak
\begin{iconcode}
globals[63] /* rnode */.dword = D\_Integer;\\
globals[63] /* rnode */.vword.integr = 1;\\
\end{iconcode}

\noindent
into

\iconline{globals[63] /* rnode */ = onedesc; }

\noindent where \texttt{onedesc} is a single descriptor that already
contains the values of the \texttt{dword} and \texttt{vword} being
assigned. This could be performed by creating several constant
decriptors for the common values such as 0 or 1.  Like the previous
optimization, this change will offer a smaller improvement to
execution speed because global descriptor assignments occur much less
frequently.

\liststyleLxli
\begin{enumerate}
\item 
When a variable is dereferenced, it is often the case that the variable location is passed in for both parameters to
the \texttt{deref} function. For example, in the following code example, \texttt{r\_frame.tend.d[7]} is the variable
being derefenced and the location where the dereferenced value is to be placed. This can be simplified by creating
another version of \texttt{deref}, perhaps named \texttt{deref1}, that takes a single argument, dereferences it, and
places the dereferenced value into the parameter location.
\end{enumerate}
\iconline{deref(\&r\_frame.tend.d[7], \&r\_frame.tend.d[7]); }

\liststyleLxlii
\begin{enumerate}
\item 
\ Another issue is redundant constant initializations. Consider the following code:
\end{enumerate}
\goodbreak
\begin{iconcode}
r\_frame.tend.d[8].dword = D\_Integer;\\
r\_frame.tend.d[8].vword.integr = 1;\\
if (!(argp[1] /* level */.vword.integr== 1) )\\
\>goto L19 /* bound */;\\
r\_frame.tend.d[8].dword = D\_Integer;\\
r\_frame.tend.d[8].vword.integr = 1;\\
\end{iconcode}


The descriptor location 8 is assigned the value of 1 and then a conditional statement is performed which is followed by
a possible \texttt{goto}. If the jump does not occur then the same descriptor location is assigned the same value over
again. Clearly the second assignment \ is wasteful and needs to be eliminated. \ This would require fairly aggressive
analysis of the intermediate code in order to catch these code sequences, but does offer the benefits of increased
execution speed and smaller code size.


A more difficult optimization that offers a substantial reduction in the size of the intermediate and executable code
deals with \ the initialization functions that set up frames. In the case of \textit{Ctree}, over 30\% of the generated
C code consists of these functions. For example, in \textit{Ctree} there are two functions named
\texttt{P06i\_set\_value\_Vtext} and \texttt{P03n\_unset\_Vbool\_coupler} which are identical except for their frame
structures, similarly defined as \texttt{PF06i\_set\_value\_Vtext} and \texttt{PF03n\_unset\_Vbool\_coupler}; however,
these structures are identical. \ A possible solution would be to write out one copy of each unique frame structure
along with its corresponding function that would initialize that frame. \ In addition to the reduction of code size
this would result in faster compilations and faster loading of the resulting executable. \ This last optimizations is
the most difficult and would require extensive changes; however, this optimization offers the best improvements in code
size, execution time, and compile time.

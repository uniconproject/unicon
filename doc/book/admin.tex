\chapter{System and Administration Tools}

In an open computing environment, users build their own tools to extend
the capabilities provided by the system. Unicon is an excellent
language for programmers who wish to control and extend their own
system. This chapter presents techniques used to write several
system utilities of interest to general users as well as system
administrators. Best of all, many of these utilities work across
multiple platforms, thanks to Unicon's high degree of
system portability. You will see examples of

\begin{itemize}
\item Traversing and examining directories and their contents.
\item Finding duplicate files.
\item Implementing a quota system for disk usage.
\item Doing your own custom backups.
\item Capturing the results of a command-line session in a file.
\end{itemize}

\section{Searching for Files}

To begin, consider a simple problem: that of finding a file whose name
matches a specified pattern. Regular expressions are commonly used to
describe the patterns to match, so you may want to link in the regular
expression library. Here is the start of a file-search application.

\iconcode{
\# \\
\# search.icn \\
\# \\
\# Search for files whose (entire) names match a pattern given \\
\# as a regular expression \\
\# \\
\# Usage: ./search {\textless}pattern{\textgreater} [dirs] \\
\ \\
link regexp
}

The application starts by processing the
\index{command-line}command-line arguments. There must be at least
one argument: the pattern to search for. Arguments following that one
are directories to search. If no directories are specified, you can use
the current working \index{directory}directory. The procedure
\texttt{findfile()} performs the actual task of searching for the
files:

\iconcode{
procedure main(args) \\
\>(*args {\textgreater} 0) {\textbar} stop("Usage:
search {\textless}pattern{\textgreater} [directories]") \\
\>pattern := pop(args) \\
\>if *args = 0 then findfile(".", pattern) \\
\>else \\
\>\>    every dir := !args do findfile(dir, pattern)\\
\> exit(0) \\
end
}

The search algorithm is a depth-first search. In each directory, check
the type of each file. If you find a directory, make a recursive call
to \texttt{findfile()}. But before you do that, check to see if the
name of the file matches the pattern.

For efficiency, since the program uses the same regular expression for
all searches, you can compile the pattern into a static variable called
\texttt{pat}. The regular expression library allows you to perform this
compilation once, the first time that \texttt{findfile()} is called,
and then reuse it in subsequent calls.

\iconcode{
procedure findfile(dir, pattern) \\
\>local d, f, s \\
\>static pat \\
\\
\>initial \{ \\
\>\>pat := RePat(pattern) {\textbar} stop("Invalid pattern ", image(pattern)) \\
\>\>\} \\
\>d := open(dir) {\textbar} \{ \\
\>\>write(\&errout, "Couldn't access ", dir, " ", \&errortext) \\
\>\>return \\
\>\>\}
}

While you read the names of the files in the directory, be sure to not
go into the special entries \texttt{"."}
and \texttt{".."} that represent the
current directory and the parent directory, respectively. Except for
these names, the directory hierarchy is a \index{tree}tree so you
don't need to check for cycles. Some file systems
support the concept of \index{link!file system}links, described in
Chapter 5; links can introduce cycles, so the code below
\index{link!recursion}recursively calls itself only on regular
directories, not on links.

\iconcode{
\>while name := read(d) do \{ \\
\>\>if name == ("." {\textbar} "..") then next \\
\>\>f := dir {\textbar}{\textbar}"/" {\textbar}{\textbar} name \\
\>\>s := stat(f) {\textbar} \{ \\
\>\>\>write(\&errout, "Couldn't stat ", f, " ", \&errortext) \\
\>\>\>next \\
\>\>\>\}
}

Here is the check of the file name against the pattern:

\iconcode{
\>\>name ? if tab(ReMatch(pat)) \& pos(0) then write(f)
}

\bigskip\noindent{\sffamily\bfseries \bf Note:}\
{\sffamily
Regular expressions do not use the same notation as file-matching
wildcards used on the command line. The regular expression notation
used by RePat() and ReMatch() is given in the documentation for the
\texttt{regexp} module in Appendix B.}

Finally, if \texttt{f} is the name of a directory, make the recursive
call. Note that since the pattern has already been compiled and stored
in a static variable, you don't need to pass it in as
a parameter for the recursive call.

\iconcode{
\>\>if s.mode[1] == "d" then findfile(f) \\
\>\>\} \\
\>close(d) \\
end
}

This is a very simple demonstration of some systems programming
techniques for Unicon. You will see this sort of depth-first traversal
of the file system again, in the section on file system backups later
in this chapter.

\section{Finding Duplicate Files}

An interesting variation on the previous program is to find files whose
contents are identical. This is valuable for those of us who make many
copies of files in various subdirectories over time, and then forget
which ones are changed. Since this task deals with lots of files, there
are some things to think about. Reading a file is an expensive
operation, so you should try to minimize the files you read. Since you
can find the length of a file without reading it, you can use that to
perform the first cut: you won't need to compare files
of different sizes. The first step, then, is to solve the simpler
problem of finding files that have the same size.

The previous program example shows how to traverse the directory
structure. For the lengths you can use a table - with each possible
length, store the names of the files of that length. Since there are
lots of files, try to be smart about what you store in the table. The
natural structure is a list. This leads to the following code:

\iconcode{
procedure scan(dir) \\
\>f := open(dir) {\textbar} \{ \\
\>\>write(\&errout, "Couldn't access ", dir, " ", \&errortext) \\
\>\>return \\
\>\>\} \\
\>while name := read(f) do \{ \\
\>\>filename := dir {\textbar}{\textbar} "/" {\textbar}{\textbar} name \\
\>\>r := stat(filename) \\
\>\>case r.mode[1] of \{ \\
\>\>\>"-" : \{ \\
\>\>\>\>/lengths[r.size] := list() \\
\>\>\>\>push(lengths[r.size], filename) \\
\>\>\>\>\} \\
\>\>\>"d" : name == ("." {\textbar} "..") {\textbar} scan(filename) \\
\>\>\>\} \\
\>\>\} \\
\>close(f) \\
end
}

The main program scans all the directories, and for each list, compares
all the files in it to each other. The global table named
\texttt{lengths} maps lengths to filenames.

\iconcode{
global lengths \\
procedure main() \\
\>lengths := table() \\
\>scan("/.") \\
\>every l := !lengths do \{ \\
\>\>if *l = 1 then next \\
\>\>find\_dups(l) \\
\>\>\} \\
end
}

For example, if in a directory there are files A, B, C, and D with
lengths of 1, 2, 5, and 2 bytes, respectively, the \texttt{lengths}
table will contain the following:

\iconcode{
\>   lengths[1] === [ "A" ] \\
\>   lengths[2] === [ "B", "D" ] \\
\>   lengths[5] === [ "C" ]
}

If a list only has one element, there is no reason to call the function
to compare all the elements together.

All of this makes sense, but in many cases there will be only one file
that has a certain size. Creating a list for each file size is a small
waste of space. What if, for the first entry, you only store the name
of the file in the table? Then if you get a second file of the same
size, you can convert the table entry to store a list. That is, in the
above example you could have

\iconcode{
\>   lengths[1] === "A" \\
\>   lengths[2] === [ "B", "D" ] \\
\>   lengths[5] === "C"
}

Now for most of the files, the program is only storing a string, and it
creates a list only where it needs one. You can say that the table is
\textit{heterogeneous} if you want to get technical about how its
elements are a mixture of strings and lists. With this change, the main
procedure becomes:

\iconcode{
global lengths \\
\ \\
procedure main() \\
\>lengths := table() \\
\>scan("/") \\
\>every l := !lengths do \{ \\
\>\>if type(l) == "string" then next \\
\>\>find\_dups(l) \\
\>\>\} \\
end
}

Instead of checking to see if the list has only one element, the code
checks to see if the value from the table is a string, and ignores
those entries.

The scan procedure has to do a little more work. Instead of initializing
the value to a list, you can use the name of the current file; if the
value already in the table is a string, create a list and add both the
name from the table and the name of the current file to the list. If
the value in the table is a list already, then you can just add the
current filename to it.

\iconcode{
\>while name := read(f) do \{ \\
\>\>filename := dir {\textbar}{\textbar} "/" {\textbar}{\textbar} name \\
\>\>r := stat(filename) \\
\>\>case r.mode[1] of \{ \\
\>\>\>"-" : \\
\>\>\>\>case type(lengths[r.size]) of \{ \\
\>\>\>\>\>"null" : lengths[r.size] := filename \\
\>\>\>\>\>"string" : \{ \\
\>\>\>\>\>\>lengths[r.size] := [lengths[r.size]] \\
\>\>\>\>\>\>push(lengths[r.size], filename) \\
\>\>\>\>\>\>\} \\
\>\>\>\>\>"list" : push(lengths[r.size], filename) \\
\>\>\>\>\>\} \\
\>\>\>\>"d" : name == ("." {\textbar} "..") {\textbar} scan(filename) \\
\>\>\>\} \\
\>\>\}
}

To compare two files together, you will of course have to read both
files. One way to do it would be to read in the files to memory and
compare them, but that would take a lot of space. Most files even when
they have the same size will probably be different; you only need to
read the files until you find a difference. At the same time, you
shouldn't read the files one byte at a time, since the
I/O system is optimized to read larger chunks at a time. The chunk size
to use will depend on the exact configuration of the computer the
program is running on, that is, the speed of the file reads compared to
the CPU speed and the available RAM storage.

The actual comparison is simple: keep reading chunks of both files,
failing if you find a difference and succeeding if you reach the ends
of the files without finding any.

\iconcode{
procedure compare(file1, file2) \\
\>static maxline \\
\>initial maxline := 1000 \\
\>f1 := open(file1) {\textbar} fail \\
\>f2 := open(file2) {\textbar} \{ close(f1); fail \} \\
\>while l1 := reads(f1, maxline) do \{ \\
\>\>l2 := reads(f2, maxline) \\
\>\>if l1 \~{}== l2 then \{ \\
\>\>\>every close(f1 {\textbar} f2) \\
\>\>\>fail \\
\>\>\>\} \\
\>\>\} \\
\>every close(f1 {\textbar} f2) \\
\>return \\
end
}

One technique that is sometimes used for comparing long strings and so
forth is \textit{hashing}. To use \index{hashing}hashing, you define a
function that computes an integer from the string. If the hash values
of two strings are different, you know that they cannot be the same.
However hash values being equal doesn't necessarily
imply that the strings are equal, so in the worst case scenario you
still have to compare the two strings. If you aren't
familiar with hashing, we encourage you to consult a book on algorithms
to learn more about this technique and think about how the program may
be further improved with it. One example hash function used internally
by Unicon is equivalent to:

\iconcode{
procedure hash(s) \\
\>local i := 0 \\
\\
\>every i +:= ord(s[1 to min(*s, 10)]) do \\
\>i *:= 37 \\
\>i +:= *s \\
\>return i \\
end
}

To complete the application, one piece remains: given a list of
filenames, you need to go through them all and make all the possible
comparisons. This can be done with a simple loop, calling
\texttt{compare()} to perform the actual comparisons.

\iconcode{
procedure find\_dups(l) \\
\>every i := 1 to *l do \{ \\
\>\>f1 := l[i] \\
\>\>every j := i+1 to *l do \{ \\
\>\>\>if compare(f1, l[j]) then write(f1, " == ", l[j]) \\
\>\>\>\} \\
\>\>\} \\
end
}

This is relatively inefficient: for a list of n files, it performs
n(n-1)/2 comparisons and reads each file n-1 times. In certain
situations it is possible to get by with not doing so many comparisons;
we leave this as an exercise to the reader.

\bigskip\noindent{\sffamily\bfseries \bf Tip:}\
{\sffamily
Clever use of hashing might let you get away with reading each
file just once.}

Listing 14-1 shows the complete program, with added comments, and also
some error checking. If any directory or file open fails, it prints a
message and proceeds with the processing.

\bigskip

{\sffamily\bfseries Listing 14-1}
{\sffamily\bfseries A program for finding duplicate files.}

\iconcode{
\# \\
\# duplicate.icn \\
\# \\
\# Find files in the filesystem that are identical \\
\ \\
global lengths\\
\ \\
procedure main() \\
\>lengths := table() \\
\>\# On some systems, a leading "//" in a filename may have \\
\>\# a different meaning, so we use "/." instead of just "/" \\
\>scan("/.") \\
\>every l := !lengths do \{ \\
\>\>if type(l) == "string" then next \\
\>\>find\_dups(l) \\
\>\>\} \\
\>exit(0) \\
end \\
\ \\
\# Scan all the directories and add files to the length map - \\
\# the global table "lengths" \\
procedure scan(dir) \\
\>f := open(dir) {\textbar} \{ \\
\>\>write(\&errout, "Couldn't open ", dir, "; ", \&errortext) \\
\>\>fail \\
\>\>\} \\
\>while name := read(f) do \{ \\
\>\>filename := dir {\textbar}{\textbar} "/" {\textbar}{\textbar} name \\
\>\>r := stat(filename) {\textbar} \{ \\
\>\>\>write(\&errout, "Couldn't stat ", filename, "; ", \&errortext) \\
\>\>\>next \\
\>\>\>\} \\
\ \\
\>\>\# A small optimisation: there are probably quite a few \\
\>\>\# zero-length files on the system; we ignore them all. \\
\>\>r.size {\textgreater} 0 {\textbar} next \\
\ \\
\>\>case r.mode[1] of \{ \\
\>\>\>"-" : \\
\>\>\>\>\# ordinary file \\
\>\>\>\>case type(lengths[r.size]) of \{ \\
\>\>\>\>\>\# if null, it's the first time; just store filename \\
\>\>\>\>\>"null" : lengths[r.size] := filename \\
\ \\
\>\>\>\>\>\# if string, one element already exists; create a list and make\\
\>\>\>\>\>\# sure we add both the old filename and the new one. \\
\>\>\>\>\>"string" : \{ \\
\>\>\>\>\>\>lengths[r.size] := [lengths[r.size]] \\
\>\>\>\>\>\>push(lengths[r.size], filename) \\
\>\>\>\>\>\>\} \\
\>\>\>\>\>\# There's already a list; just add the filename \\
\>\>\>\>\>"list" : push(lengths[r.size], filename) \\
\>\>\>\>\>\} \\
\>\>\>\>"d" : \\
\>\>\>\>\>\# A directory. Make sure to not scan . or .. \\
\>\>\>\>\>name == ("." {\textbar} "..") {\textbar} scan(filename) \\
\>\>\>\} \\
\>\>\} \\
\>close(f) \\
\>return "" \\
end \\
\ \\
\# Given a list of filenames, compare the contents of each with every other.\\
procedure find\_dups(l) \\
\>\# This is O(n\^{}2) \\
\>every i := 1 to *l do \{ \\
\>\>f1 := l[i] \\
\>\>every j := i+1 to *l do \{ \\
\>\>\>if compare(f1, l[j]) then write(f1, " == ", l[j]) \\
\>\>\>\} \\
\>\>\} \\
end \\
\ \\
\# Compare two files; by reading in 1000 byte chunks. This value may need\\
\# to be adjusted depending on I/O speed compared to CPU speed and memory. \\
procedure compare(file1, file2) \\
\>static maxline \\
\>initial maxline := 1000 \\
\ \\
\>\# are f1 and f2 identical? \\
\>f1 := open(file1) {\textbar} \{ \\
\>\>write(\&errout, "Couldn't open ", file1, "; ", \&errortext) \\
\>\>fail \\
\>\>\} \\
\>f2 := open(file2) {\textbar} \{ \\
\>\>close(f1) \\
\>\>write(\&errout, "Couldn't open ", file2, "; ", \&errortext) \\
\>\>fail \\
\>\>\} \\
\>while l1 := reads(f1, maxline) do \{ \\
\>\>l2 := reads(f2, maxline) {\textbar} \\
\>\>\>\# The files are supposed to be the same size! How could \\
\>\>\>\# we read from one but not the other? \\
\>\>\>stop("Error reading ", file2) \\
\>\>if l1 \~{}== l2 then \{ \\
\>\>\>every close(f1 {\textbar} f2) \\
\>\>\>fail \\
\>\>\>\} \\
\>\>\} \\
\>every close(f1 {\textbar} f2) \\
\>return \\
end
}

\section{User File Quotas}

Many computing platforms offer a filesystem \index{quota}quota facility,
where each user has only so much of the disk to store files. The
system does not allow files to grow once the
limit has been reached. However, many systems don't
have this facility, and on other systems the available quota mechanism
is not enabled because the user might have an urgent and immediate need
to exceed his or her quota for a short time.

For these uses this section presents an alternate filesystem quota
method. The quota for each user is stored in a file, and at regular
intervals (perhaps overnight) the system examines the disk usage of
each user. If it is above the quota, a message is sent. A summary
message is also sent to the administrator so that any user that is over
quota for more than a few days will be noticed.

First, declare a few global variables that will hold the strings that
are to be used in the messages that are sent:

\iconcode{
global complaint\_part1, complaint\_part2, summary\_header \\
\ \\
procedure main(args) \\
\>\# Read database of users; get disk usage for each user and \\
\>\# check against his/her quota \\
\>db := "/usr/lib/quotas/userdb" \\
\>administrator := "root" \\
\>init\_strings()
}

\subsection*{Calculating disk usage}

The next step is to read the database of users, and for every
directory, calculate the \index{disk usage}disk usage. On
UNIX systems you can just run \texttt{du} (the UNIX tool that
measures disk usage) and read its output from a pipe to obtain this
figure. The \texttt{{}-s} option tells \texttt{du} to print a summary
of disk usage; it prints the usage and the name of the directory,
separated by a tab character. If your platform doesn't
have a \texttt{du} command, how hard is it to write one in Unicon? The
\texttt{du} command is straightforward to write, using
the techniques presented in the previous two programming examples.

\iconcode{
procedure du(dir) \\
\>local s := stat(dir), d, sum := 0 \\
\ \\
\>\# If it's not a directory, just return its size \\
\>if s.mode[1] \~{}== {\textquotedblleft}d{\textquotedblright} then \\
\>\>return s.size \\
\ \\
\>\# Otherwise, find the usage of each entry and add \\
\>d := open(dir) {\textbar} fail \\
\>while filename := read(d) do sum +:= du(filename) \\
\>close(d) \\
\>return sum \\
end
}

Using this procedure, the program fills in the table of usages.

\iconcode{
\>L := read\_db(db) \\
\>owners := L[1] \\
\>quotas := L[2] \\
\>daysover := L[3] \\
\>usages := table(0) \\
\>over := table() \\
\>every dir := key(owners) do \{ \\
\>\>usages[dir] := du(dir) \\
\>\>user := owners[dir]
}

If the usage reported is greater than the quota, increment the
"days over" field. Save the results and
send all the email later; this will allow us to only send one message
to a user that owns more than one directory.

\iconcode{
\>\>if usages[dir] {\textgreater} quotas[dir] then \{ \\
\>\>\>/over[user] := [] \\
\>\>\>daysover[dir] +:= 1 \\
\>\>\>l := [dir, usages[dir], quotas[dir], daysover[dir]] \\
\>\>\>push(over[user], l) \\
\>\>\>\} \\
\>\>else  daysover[dir] := 0 \\
\>\>\} \\
\>every user := key(over) do complain(user, over[user])
}

Finally, the program saves the database and sends a summary of the
over-quota directories to the administrator.

\iconcode{
\>write\_db(db, owners, quotas, daysover) \\
\>send\_summary(administrator, owners, quotas, daysover, usages) \\
end
}

\subsection*{Sending mail messages}

Two procedures in the quota program send mail messages as their primary
task. This is done in many older system administration scripts by
executing an external mail client using the \texttt{system()} function.
Calling \index{system()}\texttt{system()} is a potential portability
problem and security hole in many applications. The quota program uses
Unicon's messaging facilities to send mail, avoiding
both of these problems.

Procedure \texttt{complain()} sends a message to the user notifying
him/her that certain directories are over quota. The entry for each
user is a list, each member of which is a record of an over-quota
directory, stored as a list. This list has the directory name, the
usage, the quota and the number of days it has been over quota.

\iconcode{
procedure complain(user, L) \\
\>msg := "Dear " {\textbar}{\textbar} user {\textbar}{\textbar} complaint\_part1 \\
\>every l := !L do \{ \\
\>\>msg {\textbar}{\textbar}:= "{\textbackslash}t" {\textbar}{\textbar}
l[1] {\textbar}{\textbar} "{\textbackslash}t" {\textbar}{\textbar}
l[2] {\textbar}{\textbar} "{\textbackslash}t" {\textbar}{\textbar}
l[3] {\textbar}{\textbar} "{\textbackslash}t" {\textbar}{\textbar}
l[4] {\textbar}{\textbar} "{\textbackslash}n" \\
\>\} \\
\>msg {\textbar}{\textbar}:= complaint\_part2 \\
\>m := open("mailto:"{\textbar}{\textbar} user, "m", "Subject: Over Quota") \\
\>write(m, msg) \\
\>close(m) \\
end
}

Procedure \texttt{send\_summary()} sends mail to the administrator
summarizing all over-quota directories. It uses the function
\index{key()}\texttt{key()} to generate the indexes for tables
\texttt{usages}, \texttt{quotas}, \texttt{owners}, and
\texttt{daysover}, which are maintained in parallel. This use of
\texttt{key()} is quite common. It might be possible to combine all
these parallel tables into one big table and eliminate the need to call
\texttt{key()}.

\iconcode{
procedure send\_summary(admin, owners, quotas, daysover, usages) \\
\>m := open("mailto:"{\textbar}{\textbar} admin, "m", "Subject: Quota Summary") \\
\>write(m, summary\_header) \\
\>every dir := key(owners) do \\
\>\>if usages[dir] {\textgreater} quotas[dir] then \{ \\
\>\>\>writes(m, dir, "{\textbackslash}t", owners[dir], "{\textbackslash}t",
 usages[dir]{\textbar}{\textbar}"/"{\textbar}{\textbar}quotas[dir], "{\textbackslash}t", \\
\>\>\>\>daysover[dir]) \\
\>\>\>\# Flag anything over quota more than 5 days \\
\>\>\>if daysover[dir] {\textgreater} 5 then writes(m, " ***") \\
\>\>\>write(m) \\
\>\>\>\} \\
\>close(m) \\
end
}

\subsection*{The quota database}

The database is stored as a plain text file so that the system
administrator can easily make changes to it. It has four fields,
separated by white space (spaces or tabs): a directory, the owner of
the directory, the quota, and the number of days the directory has been
over quota. Procedure \texttt{read\_db()} reads in the database. Blank
lines or lines starting with '\#' are
ignored.

\iconcode{
procedure read\_db(db) \\
\>owners := table() \\
\>quotas := table(0) \\
\>daysover := table(0) \\
\>dbf := open(db) {\textbar} stop("Couldn't open ",db) \\
\>while line := read(dbf) {\textbar}{\textbar} "{\textbackslash}t" do \\
\>\>line ? \{ \\
\>\>\>tab(many('{\textbackslash}t')) \\
\>\>\>if pos(0) {\textbar} ="\#" then next \\
\>\>\>dir := tab(upto('{\textbackslash}t')); \ tab(many('{\textbackslash}t')) \\
\>\>\>user := tab(upto('{\textbackslash}t'));\ tab(many('{\textbackslash}t')) \\
\>\>\>quota := tab(upto('{\textbackslash}t'));\ tab(many('{\textbackslash}t')) \\
\>\>\>days := tab(0) {\textbar} "" \\
\>\>\>\# The "days" field can be absent in which case 0 is \\
\>\>\>\# assumed. \\
\>\>\>if days == "" then days := 0
}

If multiple quota lines occur for a directory, the tables must be
updated appropriately. The semantics of the tables require varying
approaches. The owners table writes a warning message if quota lines
with different owners for the same directory are found, but otherwise
the owners table is unaffected by multiple entries. The actual quotas
table allows multiple quota lines for a directory; in which case the
quotas are added together. The daysover table retains the maximum value
any quota line is overdue for a directory.

\iconcode{
\>\>\>if {\textbackslash}owners[dir] \~{}== user then \\
\>\>\>\>write(\&errout, "Warning: directory ", dir, " has more than one owner.") \\
\>\>\>owners[dir] := user \\
\>\>\>quotas[dir] +:= quota \\
\>\>\>daysover[dir] := days \\
\>\>\>\} \\
\>close(dbf) \\
\>return [owners, quotas, daysover] \\
end
}

Procedure \texttt{write\_db()} rewrites a quota database with current
quota information. Notice how the code preserves the
\index{comment}comments and the blank lines that were present in the
database file. This is very important when dealing with human-editable
files. It also writes to a temporary file and then renames it to the
correct name. This ensures that a consistent copy of the database is
always present.

\iconcode{
procedure write\_db(db, owners, quotas, daysover) \\
\>new\_db := db {\textbar}{\textbar} ".new" \\
\>db\_old := open(db) \\
\>db\_new := open(new\_db, "w") {\textbar} stop("Couldn't open", new\_db) \\
\>while line := read(db\_old) do \{ \\
\>\>line ? \{ \\
\>\>\>tab(many('{\textbackslash}t')) \\
\>\>\>if pos(0) {\textbar} ="\#" then \{ \\
\>\>\>\>write(db\_new, line) \\
\>\>\>\>next \\
\>\>\>\>\} \\
\>\>\>dir := tab(upto('{\textbackslash}t')) \\
\>\>\>write(db\_new, dir, "{\textbackslash}t", owners[dir],
"{\textbackslash}t", quotas[dir], "{\textbackslash}t", daysover[dir]) \\
\>\>\>\} \\
\>\>\} \\
\>close(db\_old) \\
\>close(db\_new) \\
\>rename(db, db {\textbar}{\textbar} ".bak") \\
\>rename(new\_db, db) \\
end
}

Lastly, procedure \texttt{init\_strings()} initializes global strings
used for email messages. Concatenation is used to improve the
readability of long strings that run across multiple lines.

\iconcode{
procedure init\_strings() \\
\>complaint\_part1 := ":{\textbackslash}n"\ {\textbar}{\textbar} \\
\>\>"The following directories belonging to youare"{\textbar}{\textbar} "over their
quota:{\textbackslash}n{\textbackslash}n"\ {\textbar}{\textbar} \\
\>\>"Directory \ \ \ {\textbackslash}tUsage {\textbackslash}tQuota {\textbackslash}tDays
Over{\textbackslash}n" \\
\>complaint\_part2 := "{\textbackslash}nPlease take care of it." \\
\>summary\_header := "{\textbackslash}n"\ {\textbar}{\textbar}  \\
\>\>"Over-quota users{\textbackslash}n{\textbackslash}n"\ {\textbar}{\textbar} \\
\>\>"Directory \ \ {\textbackslash}tOwner {\textbackslash}tUsage/Quota {\textbackslash}tDays
Over{\textbackslash}n" \\
end
}

\section{Capturing a Shell Command Session}

Many applications including debugging and training can benefit from the
ability record a transcript of a session at the computer. This
capability is demonstrated by the following program, called
\texttt{script}. The \texttt{script} program uses a feature of POSIX
systems called the \textit{pty}. This is short for
\index{pseudo-tty}pseudo-tty. It is like a bi-directional pipe with the
additional property that one end of it looks exactly like a
conventional tty. The program at that end can set it into
"no-echo" mode and so forth, just like it
can a regular terminal. This application's portability
is limited to the UNIX platforms.

The \texttt{script} program has only one option: if \texttt{{}-a} is
used, output is appended to the transcript file instead of overwriting
it. The option is used to set the second argument to \texttt{open()}:

\iconcode{
\# script: capture a script of a shell session (as in BSD) \\
\# Usage: script [-a] [filename] \\
\# filename defaults to "typescript" \\
\ \\
procedure main(L) \\
\>if L[1] == "-a" then \{ \\
\>\>flags := "a"; pop(L) \\
\>\>\} \\
\>else flags := "w"
}

Now the program must find a pty to use. One method is to go
down the list of pty device names in sequence until an
\texttt{open()} succeeds; then call procedure \texttt{capturesession()},
to perform the actual logging. On POSIX systems the pty
names are of the form \texttt{\textit{/dev/ptyp-s0-a}}. The tty
connected to the other end of the pipe then has the name
\texttt{\textit{/dev/ttyXY}}, where \texttt{X} and \texttt{Y} are the
two characters from the pty's name.


\iconcode{
\>\# Find a pty to use \\
\>every c1 := !"pqrs" do \\
\>\>every c2 := !(\&digits {\textbar}{\textbar} "abcdef") do \\
\>\>\>if pty := open("/dev/pty" {\textbar}{\textbar} c1 {\textbar}{\textbar} c2,
"rw") then \{ \# Aha! \\
\>\>\>\>capturesession(fname := L[1] {\textbar} "typescript", pty, c1
{\textbar}{\textbar} c2, flags) \\
\>\>\>\>stop("Script is done, file ", image(fname)) \\
\>\>\>\>\} \\
\>stop("Couldn't find a pty!") \\
end
}

\bigskip\noindent{\sffamily\bfseries \bf Note:}\
{\sffamily
If you do not have read-write permissions on the pseudotty device the
program uses, the program will fail. If this program does not work,
check the permissions on the /dev/tty* device it is trying to use. }

The \texttt{script} program uses the \index{system()}\texttt{system()}
function, executing the user's shell with the standard
input, standard output, and standard error streams all redirected to be
the tty end; then it waits for input (using
\index{select()}\texttt{select()}) either from the user or from the
spawned program. The program turns off echoing at its end, since the
spawned program will be doing the echoing. The program sends any input
available from the user to the spawned shell; anything that the shell
sends is echoed to the user, and also saved to the script file.

\iconcode{
procedure capturesession(scriptfile, pty, name, flags) \\
\>f := open(scriptfile, flags) {\textbar} stop("Couldn't open ", image(scriptfile)) \\
\>tty := open("/dev/tty" {\textbar}{\textbar} name, "rw") {\textbar} stop("Couldn't open tty!") \\
\>shell := getenv("SHELL") {\textbar} "/bin/sh" \\
\>system([shell, "-i"], tty, tty, tty, "nowait") \\
\ \\
\>\# Parent \\
\>close(tty) \\
\>system("stty raw -echo") \\
\ \\
\>\# Handle input \\
\>while L := select(pty, \&input) do \{ \\
\>\>if L[1] === \&input then writes(pty, reads()) {\textbar} break \\
\>\>else if L[1] === pty then \{ \\
\>\>\>writes(f, inp := reads(pty)) {\textbar} break \\
\>\>\>writes(inp) \\
\>\>\>\} \\
\>\>\}
}

When \texttt{script} gets an EOF on either stream, it quits processing
and closes the file, after resetting the parameters of the input to
turn echoing back on.

\iconcode{
\>(\&errno = 0) {\textbar} write(\&errout, "Unexpected error: ", \&errortext) \\
\>system("stty cooked echo") \\
\>close(f) \\
end
}

\section{Filesystem Backups}

By now you have probably been told a few thousand times that regular
\index{backups}backups of your files are a good idea. The problem
arises when you are dealing with a system with a large amount of file
storage, like modern multi-user systems. For these systems,
\textit{incremental backups} are used. Incremental backups exploit the
fact that a very large number of files on the system change rarely, if
ever. There is no need to save them all to the backup medium every
time. Instead, each backup notes the last time that a backup was
performed, and only saves files that have been modified since then.

Each backup is given a number; the files in backup n were
modified later than the last backup of a lower number. A Level 0 backup
saves all the files on the system.

This section presents an incremental backup utility called
\texttt{backup}. The \texttt{backup} utility saves all the files in a
directory specified with the \texttt{{}-o} flag. Typically this will be
the external backup storage, like a floppy disk (for small backups) or
a Zip disk. The program re-creates the directory structure on the
external device so that files may easily be recovered. The disadvantage
of this strategy is that it does not compress the whole archive
together, and therefore requires more storage than is strictly
necessary. On the positive side, this approach avoids the fragility of
compressed archives, in which the loss of even a small amount of data
can render the whole archive unreadable.

\bigskip\noindent{\sffamily\bfseries \bf Note:}\
{\sffamily
This program only saves to media that has a directory structure on which
regular files may be written, such as jump drives. It does not work on backup
devices such as tape drives that require media to be written in a
proprietary format.}

Another feature of this backup program is that certain directories can
be automatically excluded from the backup, such as temporary
directories like \texttt{/tmp} on UNIX systems. One directory that
{\em must\/} be excluded is the output device itself, or you will
find that a very large amount of storage is needed! One of the best
parts about \texttt{backup} is that you can modify this program to suit
your needs: file compression, error recovery, support for multiple
discs, or anything else that you require.

\iconcode{
\# \\
\# backup.icn - incremental filesystem backups \\
\# \\
\# Usage: \\
\# \ \ ./backup [-nlevel] [-ooutput] [dir] \\
\# \\
\# Save all files that have changed since the last backup of higher level\\
\# (a level 0 backup is the highest level and saves all files; it is the\\
\# default). The files are all saved to the directory "output", which is \\
\# probably a mounted backup device like a flash drive. \\
\# \\
\# Example: \\
\#\>backup -n3 -o/mnt/zip /home/bob \\
\ \\
link options \\
\ \\
global dbase, exclude, levels \\
global output, last \\
\ \\
procedure main(args) \\
\>dbase := "/var/run/backups.db" \\
\>exclude := ["/mnt", "/tmp", "/dev", "/proc"] \\
\ \\
\>\# Process arguments \\
\>opt := options(args, "-n+ -o:") \\
\>level := integer({\textbackslash}opt["n"]) {\textbar} 0 \\
\>output := opt["o"] \\
\>dir := args[1] {\textbar} "/" \\
\ \\
\>{\textbackslash}output {\textbar} stop("An output directory (option -o) must be specified!") \\
\>if level {\textless} 0 {\textbar} level {\textgreater} 9 then stop("Only levels 0..9 can be used.") \\
\ \\
\>\# Get the time of the previous lower-numbered backup \\
\>last := get\_time(level)
\ \\
\>\# Now look for files newer than "last" \\
\>traverse(dir) \\
\ \\
\>\# Write the database \\
\>save\_time(level) \\
end
}

Procedure \index{traverse}\texttt{traverse}\texttt{()} is the
interesting part of the program. It recursively descends the filesystem
hierarchy, saving all the files it finds that are newer than the last
backup. When a recent plain file is found, the procedure
\texttt{copy\_file()} is called.

\iconcode{
procedure traverse(dir) \\
\>\# Skip excluded directories \\
\>if dir == !exclude then return \\
\ \\
\>\# Read all the files; for any non-special files, copy them \\
\>\# over to the output dir, creating directories as necessary \\
\>d := open(dir) {\textbar} \{ \\
\>\>write(\&errout, "Couldn't stat ", dir, " ", \&errortext) \\
\>\>return \\
\>\>\} \\
\>if dir[-1] \~{}== "/" then dir {\textbar}{\textbar}:= "/" \\
\>while name := read(d) do \{ \\
\>\>if name == ("." {\textbar} "..") then next \\
\>\>s := stat(dir {\textbar}{\textbar} name) {\textbar} \{ \\
\>\>\>write(\&errout, "Couldn't stat ", dir {\textbar}{\textbar} name, " ", \&errortext) \\
\>\>\>next \\
\>\>\>\} \\
\>\>if s.mode[1] == "d" then traverse(dir {\textbar}{\textbar} name) \\
\>\>else \{ \\
\>\>\>\# Only save plain files \\
\>\>\>if s.mode[1] == "-" \& s.ctime {\textgreater} last then copy\_file(dir, name) \\
\>\>\>\} \\
\>\>\} \\
end
}

To copy a file, you must first ensure that its parent directory exists.
If it doesn't, the parent directory is created; then
the file itself is copied. For efficiency, \texttt{backup} uses the
system program (\texttt{cp} on UNIX) to copy the file. When directories
are created, \texttt{backup} copies the owner and mode from the
directory being backed up.

\bigskip\noindent{\sffamily\bfseries \bf Note:}\
{\sffamily
This program must be run with administrator privileges for it to be able
to read all the files on the system and also to be able to set the
owner and mode.}

\iconcode{
procedure copy\_file(dir, name) \\
\>\# First, make sure the directory exists \\
\>mkdir\_p(output, dir) \\
\>system("cp " {\textbar}{\textbar} dir {\textbar}{\textbar} "/"
{\textbar}{\textbar} name {\textbar}{\textbar} "
" {\textbar}{\textbar} output {\textbar}{\textbar}
"/" {\textbar}{\textbar} dir) \\
end \\
\ \\
procedure mkdir\_p(prefix, dir) \\
\>\# The name is supposed to be reminiscent of "mkdir -p" \\
\>\# Start at the first component and keep going down it, \\
\>\# copying mode and owner. \\
\>dir {\textbar}{\textbar}:= "/" \\
\>d := "" \\
\>dir ? while comp := tab(upto('/')) do \{ \\
\>\>tab(many('/')) \\
\>\>d {\textbar}{\textbar}:= "/" {\textbar}{\textbar} comp \\
\>\>if {\textbackslash}stat(prefix {\textbar}{\textbar} d) then \{ \\
\>\>\>\# The directory doesn't exist; create it. d is the \\
\>\>\>\# directory being copied over; get its uid and mode. \\
\>\>\>s := stat(d) \\
\>\>\>mkdir(prefix {\textbar}{\textbar} d, s.mode[2:11]) \\
\>\>\>chown(prefix {\textbar}{\textbar} d, s.uid, s.gid) \\
\>\>\>\} \\
\>\>\} \\
end
}

The database file is very simple: for every level, the date of the last
backup at that level is stored. Dates are stored in the system native
format so that comparisons with file modification dates can be easily
performed. If no earlier backup is found, procedure
\texttt{get\_time()} returns the earliest possible time (the epoch);
all files will have newer modified times, and therefore be backed up.

All the dates found are stored in a global table so that they will be
accessible when \texttt{backup} writes out the database later.

\iconcode{
procedure get\_time(n) \\
\>\# Get the date of earlier backup \\
\>levels := table() \\
\>f := open(dbase) \\
\ \\
\>while line := read({\textbackslash}f) do \\
\>\>line ? \{ \\
\>\>\>lev := integer(tab(upto(' '))) \\
\>\>\>move(1) \\
\>\>\>date := tab(0) \\
\>\>\>levels[lev] := date \\
\>\>\>\} \\
\>close({\textbackslash}f) \\
\>every i := integer(!\&digits) do \\
\>\>if i {\textless} n then prev := {\textbackslash}levels[i] \\
\>/prev := 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \# default: the epoch \\
\>return prev \\
end
}

Finally, the program saves the database of dates. It fetches the current
time to save with the current level, and deletes all
higher-numbered backups from the database.

\iconcode{
procedure save\_time(n) \\
\>levels[n] := \&now \\
\ \\
\>f := open(dbase, "w") {\textbar} stop("Couldn't open table ", dbase) \\
\>every i := integer(!\&digits) do \\
\>\>if i {\textless}= n then write(f, i, " ", {\textbackslash}levels[i]) \\
\>\>else break \\
\>close(f) \\
end
}

\section{Filtering Email}

Unicon's messaging facilities can be used for filtering
email messages obtained from a POP server. A filtering rule has two
components: a pattern to look for, and an action to perform if the
string is found. The action to be perform can take a few forms: the
message can be saved in a folder; it can be deleted; or it can be
forwarded to some other address. We can use a record to represent a
rule:

\iconcode{
record rule(pattern, action, args)
}

Here are some example rules represented as records:

\iconcode{
\>rule("From: .*spammer{\textbackslash}.com", "delete") \\
\>rule("From: .*unicon-list@lists{\textbackslash}.sourceforge{\textbackslash}.net", "save",
"folders/unicon") \\
\>rule("Subject: .*xyzzy", "forward\textrm{"}
\textrm{"}\href{mailto:shamim@home-domain.org}{shamim@home-domain.org}")
}


\bigskip

We read all the rules from a file and use them to filter all messages.
To connect \ to the POP server, we need some parameters: the server to
connect to, the username and the password. These values are stored in a
parameter file that we read. The parameters from the file can be stored
in a global table called \texttt{params}. (We will deal with reading
the file later.) First, we connect to the POP server and for every
message, invoke the filter:

\iconcode{
\>params := get\_parameters() \\
\>server := {\textbackslash}params["server"] {\textbar} stop("No server specified in .popfilter file") \\
\>user := {\textbackslash}params["user"] {\textbar} stop("No user specified in .popfilter file") \\
\>password := {\textbackslash}params["password"] {\textbar} \\
\>\>stop("No password specified in .popfilter file") \\
\>{\textbackslash}params["inbox"] {\textbar} stop("No inbox specified in .popfilter file") \\
\ \\
\>url := "pop://" {\textbar}{\textbar} user {\textbar}{\textbar} ":"
{\textbar}{\textbar} password {\textbar}{\textbar} "@" {\textbar}{\textbar} server \\
\>s := open(url, "m") {\textbar} stop("Couldn't connect to ", image(url)) \\
\>while filter(pop(s), rules) do \\
\>\>\# Make sure there are no errors \\
\>\>if s["Status-Code"] {\textgreater}= 300 then \{ \\
\>\>\>close(s) \\
\>\>\>stop(\&progname, ": POP error: ", s["Status-Code"], \\
\>\>\>\>" ", s["Reason-Phrase"] {\textbar} "") \\
\>\>\>\}
}

After reading each message, we make sure that there
wasn't an error in talking to the POP server -- if
there was one, we print the error and exit.

The filtering procedure tries to match the message against every rule;
if one matches, it hands the message off to the action procedure. If no
rule matches, the message is saved to the default folder (the inbox).

\iconcode{
procedure filter(message, rules) \\
\>local filter\_rule \\
\\
\>every filter\_rule := !rules do \\
\>\>if message? ReFind(filter\_rule.pattern) then \\
\>\>\>perform(filter\_rule.action, filter\_rule.args, message) {\textbar} \\
\>\>\>\>write(\&errout, "Error in ",image(filter\_rule.action), \\
\>\>\>\>\>" ", image(filter\_rule.args)) \\
\>\# No action matched so we save it in the inbox \\
\>perform("save", params["inbox"], message) \\
end
}

Since the patterns are regular expressions, we link in the IPL regexp
package for the procedure \texttt{ReFind()} that will do the pattern
matching.

\iconcode{
procedure perform(action, args, message) \\
\>local procname\\
\\
\>procname := {\textbackslash}proc("filterproc\_" {\textbar}{\textbar} action, 2) {\textbar}\\
\>\>stop(\&progname, ": action ", image(action), " unknown.")\\
\>procname(message, args) {\textbar} fail\\
\>return ""\\
end}

We use Unicon's string invocation (and
we'd better remember to put \texttt{invocable all} at
the top of the program) to call the procedure associated with each
defined action. The function \texttt{proc()} tries to find the
procedure with the right name; if it fails, it is an unknown action.
The names of these procedures all have the form
{\textquotedblleft}filterproc\_{\textquotedblright} appended with the
name of the action. We make sure that the procedures succeed if there
was no error in performing the action.

\iconcode{
procedure filterproc\_delete(message, args)\\
\>return "" \ \ \ \ \ \ \ \ \ \ \ \ \ \ \# We don't have to do anything\\
end\\
\\
procedure filterproc\_save(message, filename)\\
\>local f\\
\\
\>f := open(filename, "a") {\textbar} fail\\
\>write(f, message)\\
\>close(f)\\
\>return ""\\
end\\
\\
procedure filterproc\_forward(message, address)\\
\>local subject, s\\
\\
\>\# Find the subject of the message and use that\\
\>message? (tab(find("Subject: ")) \& subject := tab(upto('{\textbackslash}n')))\\
\>subject := "Subject: " {\textbar}{\textbar} {\textbackslash}subject\\
\\
\>s := open("mailto://" {\textbar}{\textbar} address, "m", subject) {\textbar} fail\\
\>write(s, message)\\
\>close(s)\\
\>return ""\\
end
}

It would be easy to implement an action that sends messages to external
programs -- in procedure \texttt{perform()}, if the first character of
the action is the pipe symbol
{\textquotedblleft}{\textbar}{\textquotedblright} we can open a pipe
and write the message to it instead of calling the right action
procedure. (This would be a good {\textquotedblleft}exercise left to
the reader!{\textquotedblright})

We still need to read the files and set up the \texttt{params} table and
the list of rules. It is a good idea to allow blank lines and comments
in files we read, since humans will be editing these files and we like
comments to remind ourselves what things do. We need a procedure that
reads a file and strips out comments and blank lines:

\iconcode{
\# Read a line from a file, skipping comments and blank lines\\
procedure getline(f)\\
\>local line, s\\
\\
\>while line := read(f) do line? \{\\
\>\>s := tab(upto('\#') {\textbar} 0)\\
\>\>if *trim(s) = 0 then next\\
\>\>return s\\
\>\>\}\\
end
}

We read the POP parameters from a file named \texttt{.popfilter} in the
user's home directory and return a table of name-value
pairs. The global variable \texttt{WS} is a cset that contains the
space and tab characters; it is initialized in \texttt{main()}, when
the program first starts executing.

\iconcode{
\# Read the \~{}/.popfilter file and return a table of name -{\textgreater} value pairs\\
procedure get\_parameters()\\
\>local f, P := table(), line\\
\\
\>f := open(getenv("HOME") {\textbar}{\textbar} "/.popfilter") {\textbar} return P\\
\\
\>while line := getline(f) do line ? \{\\
\>\>pname := tab(upto(WS))\\
\>\>tab(many(WS))\\
\>\>P[pname] := tab(0)\\
\>\>\}\\
\>close(f)\\
\>return P\\
end
}

The filtering rules are read from the file named on the command line.
The pattern is separated from the action by an exclamation point, and
(as usual) comments, blank lines and whitespace (around the
{\textquotedblleft}!{\textquotedblright}) are allowed. Whitespace
inside the regular expression is significant and should not be
discarded so we use \texttt{trim()} to make sure we only remove
trailing whitespace. Searches are anchored to the begin of line so we
can easily look for individual headers; instead of separating a message
into lines and using the {\textquotedblleft}beginning of
line{\textquotedblright} regular expression operator, we simply we add
a newline character to the front of the pattern.

\iconcode{
\# Read the file and return a list of rules. All the work is\\
\# actually done in getline() and parse()\\
procedure read\_rulefile(filename)\\
\>local f, rules := [ ]\\
\\
\>f := open(filename) {\textbar} fail\\
\>while push(rules, parse(getline(f)))\\
\>close(f)\\
\>return rules\\
end \\
\ \\
\# Parse a line into a pattern, an action, and optionally\\
\# arguments to the action.\\
procedure parse(s)\\
\>local regexp, action\\
\\
\>s ? \{\\
\>\>tab(many(WS))\\
\>\>regexp := tab(upto('!')) \& move(1)\\
\>\>tab(many(WS))\\
\>\>action := tab(upto(WS) {\textbar} 0)\\
\>\>pos(0) {\textbar} (tab(many(WS)) \& args := tab(0))\\
\>\>\}\\
\>return rule("{\textbackslash}n" {\textbar}{\textbar} trim({\textbackslash}regexp),
{\textbackslash}action, args)\\
end
}

Here is an example action file that includes the example rules from
above:

\iconcode{
\# Flush evil spammers!\\
From: .*spammer{\textbackslash}.com \ \ \ \ \ \ \ !delete\\
Subject: .*MAKE MONEY FAST \ !delete \ \ \ \# Got enough, thanks!\\
\\
\# Cool people get special attention\\
From: .*unicon-list@lists{\textbackslash}.sourceforge{\textbackslash}.net
\ !save folders/unicon\\
From: .*(parlett{\textbar}jeffery{\textbar}pereda) \ \ \ !save folders/urgent\\
\\
\# The secret password!! Forward it to the pager.\\
Subject: .*xyzzy \ \ \ \ \ \ \ \ \ \ \ !forward
\href{mailto:pager@shamims-domain.org}{pager@shamims-domain.org}
}

And here's an example .popfilter file:

\iconcode{
\# Settings for popfilter.icn, a POP client and email filter\\
\# July 2002\\
\\
\# Where incoming mail is stored locally\\
inbox /var/mail/shamim\\
\\
\# The POP server\\
server jantar\\
\\
\# Remember, this is the username and password on jantar\\
user spm\\
password Xyz!1234
}

We have introduced the main procedure in pieces; here it is all in one
place:

\iconcode{
link regexp\\
record rule(pattern, action, args)\\
global WS\\
\\
\# Email and POP parameters\\
global params\\
\\
\# We're using string invocation\\
invocable all\\
\\
procedure main()\\
\>local server, user, password\\
\\
\>WS := ' {\textbackslash}t' \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \# whitespace\\
\>params := get\_parameters()\\
\>server := {\textbackslash}params["server"] {\textbar}
stop("No server specified in .popfilter file")\\
\>user := {\textbackslash}params["user"] {\textbar} stop("No user specified in .popfilter file")\\
\>password := {\textbackslash}params["password"]
{\textbar} stop("No password specified in .popfilter file")\\
\>{\textbackslash}params["inbox"] {\textbar} stop("No inbox specified in .popfilter file")\\
\>if *args = 0 then stop("Usage: ", \&progname, " filter-rule-file")\\
\\
\>url := "pop://" {\textbar}{\textbar} user {\textbar}{\textbar} ":"
{\textbar}{\textbar} password {\textbar}{\textbar} "@" {\textbar}{\textbar} server\\
\\
\>filter\_rules := read\_rulefile(args[1]) {\textbar}\\
\>\>stop("Couldn't read filter rules from ", image(args[1]))\\
\>filter(testmsg(), filter\_rules)\\
\\
\>s := open(url, "m") {\textbar} stop("Couldn't connect to ", image(url))\\
\\
\>while filter(pop(s), filter\_rules) do\\
\>\>if s["Status-Code"] {\textgreater}= 300 then \{\\
\>\>\>close(s)\\
\>\>\>stop(\&progname, ": POP error: ", s["Status-Code"],
" ", s["Reason-Phrase"] {\textbar} "")\\
\>\>\>\}\\
\>close(s)\\
end
}

The complete program \texttt{popfilter.icn} can be obtained from the
book's website. There are still a few things this
program would need to be truly useful. For example, it should allow
non-anchored searches, and the user should be able to specify whether
case is significant while looking for a pattern -- or perhaps a
part of a pattern may be case sensitive by itself. Also, what if
we want a {\textquotedblleft}!{\textquotedblright} in the regular
expression? We hope that you will be inspired to make these
additions yourself.

\section{Summary}

Writing utilities and system administration tools is easy in Unicon.
These programs rely on the system facilities described in
Chapter 5. While we do not advocate using Unicon in every case,
it is an advantage that your applications language is also an
effective scripting language. Ordinary programs can easily take on
scripting tasks, and programs that might otherwise be written in a
scripting language have Unicon's cleaner design and
more robust set of control and data structures available.


\bigskip
